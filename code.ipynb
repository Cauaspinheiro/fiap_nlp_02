{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> FIAP - Faculdade de Informatica e Administração Paulista\n",
        "\n",
        "## Disciplina de Processamento de Linguagem Natural\n",
        "\n",
        "### Checkpoint 02 - Extração de Informações de um Documento de Texto\n",
        "\n",
        "Integrantes:\n",
        "\n",
        "- **Cauã Pinheiro** - 98319\n",
        "- **Emilly Oliveira** - 97915\n",
        "- **Guilherme Richetto** - 550407\n",
        "- **Vitor Manzoli** - 551551\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importando as bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy\n",
            "  Using cached spacy-3.7.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Collecting click (from nltk)\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting joblib (from nltk)\n",
            "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Downloading regex-2024.4.28-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from nltk) (4.66.2)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
            "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
            "  Using cached murmurhash-1.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
            "  Using cached cymem-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
            "  Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
            "  Downloading thinc-8.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
            "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
            "  Using cached srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
            "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
            "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
            "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting smart-open<7.0.0,>=5.2.1 (from spacy)\n",
            "  Using cached smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
            "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2 (from spacy)\n",
            "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting setuptools (from spacy)\n",
            "  Downloading setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy) (23.2)\n",
            "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
            "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
            "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic-core==2.18.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
            "  Downloading pydantic_core-2.18.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
            "  Using cached blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
            "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
            "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->spacy)\n",
            "  Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Downloading marisa_trie-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading spacy-3.7.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hUsing cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Using cached cymem-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
            "Downloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached murmurhash-1.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.18.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.4.28-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.2/785.2 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
            "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Using cached srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (490 kB)\n",
            "Downloading thinc-8.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.1/920.1 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
            "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "Downloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Using cached blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
            "Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading marisa_trie-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, setuptools, regex, pydantic-core, murmurhash, MarkupSafe, joblib, cloudpathlib, click, catalogue, blis, annotated-types, typer, srsly, pydantic, preshed, nltk, marisa-trie, jinja2, language-data, confection, weasel, thinc, langcodes, spacy\n",
            "Successfully installed MarkupSafe-2.1.5 annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 click-8.1.7 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 jinja2-3.1.3 joblib-1.4.0 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.1.0 murmurhash-1.0.10 nltk-3.8.1 preshed-3.0.9 pydantic-2.7.1 pydantic-core-2.18.2 regex-2024.4.28 setuptools-69.5.1 smart-open-6.4.0 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.4 wasabi-1.1.2 weasel-0.3.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install nltk spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rGk6m-lR2Pw",
        "outputId": "efe460a3-5363-4377-c314-d8b483b7de9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pt-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.7.0/pt_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from pt-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (69.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /home/cauaspinheiro/dev/fiap/natural_languages_01/.venv/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.1.0)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all-corpora'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package names to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package pil to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package qc to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all-corpora\n",
            "[nltk_data] Downloading collection 'all-nltk'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2022 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to\n",
            "[nltk_data]    |     /home/cauaspinheiro/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all-nltk\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import heapq\n",
        "import spacy\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "nltk.download(\"all-corpora\")\n",
        "nltk.download(\"all-nltk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lendo o arquivo\n",
        "\n",
        "Vamos ler o arquivo e limpar o texto para que possamos extrair as informações necessárias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "czBeOefHR-7e",
        "outputId": "5271821e-8b7b-4eb7-b495-c71f4545438c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Pela primeira vez, o Irã realizou ataques diretos contra o território de Israel neste sábado (13/4). No meio da noite de sábado, alertas de ataque aéreo dispararam em Israel. Os residentes procuraram abrigo enquanto explosões eram ouvidas e as defesas aéreas eram ativadas. As interceptações iluminaram o céu noturno em vários lugares do país, enquanto muitos drones e mísseis foram abatidos pelos aliados de Israel antes de chegarem ao território israelense. Pelo menos nove países estiveram envolvidos na escalada militar – com projéteis disparados do Irã, Iraque, Síria e Iêmen e abatidos por Israel, pelos EUA e pela França, bem como pela Jordânia. Uma represália era esperada. O Irã havia prometido retaliar depois de um ataque ao seu consulado na Síria, no dia 1º de abril, que atribuiu a Israel (embora Israel não tenha confirmado ser o autor). Permanecer alerta As forças israelenses estão em alerta máximo e \"monitorando todos os alvos\". Após o ataque, o primeiro-ministro de Israel, Benjamin Netanyahu, afirmou que \"juntos venceremos\", mas não está claro qual será a resposta de Israel. O presidente Biden disse ter reafirmado \"o firme compromisso da América com a segurança de Israel\". O porta-voz das Forças de Defesa de Israel, contra-almirante Daniel Hagari, disse que alguns mísseis iranianos atingiram o interior de Israel, causando pequenos danos a uma base militar, mas sem vítimas. O serviço de ambulância de Israel disse que uma menina beduína de sete anos foi ferida por estilhaços de destroços na região sul de Arad. Hagari disse que o ataque em larga escala foi uma \"grande escalada\" e disse que Israel e seus aliados operaram com força total para defender Israel. Ele disse que o Irã disparou mais de 300 projéteis contra Israel durante a noite, 99% dos quais foram abatidos. Ele acrescentou que alguns dos lançamentos chegaram do Iraque e do Iêmen. O ministro da Defesa de Israel, Yoav Gallant, disse que \"muito poucos danos foram causados\", mas alertou que \"a campanha ainda não terminou\" e disse que Israel deve \"permanecer alerta\". Quase todos Ao expressar forte condenação pelo ataque, o presidente dos Estados Unidos, Joe Biden, disse que os EUA ajudaram Israel \"a derrubar quase todos\" os mísseis e drones. \"O Irã e os seus representantes que operam a partir do Iêmen, Síria e Iraque lançaram um ataque aéreo sem precedentes contra instalações militares em Israel\", disse Biden. Em um comunicado oficial, o Irã afirmou que o ataque foi nomeado \"Operação Promessa Verdadeira\" e disse que lançou \"dezenas de mísseis e drones contra alvos específicos\" em Israel. A declaração militar do Irã diz que o ataque está relacionado a \"crimes repetidos\" de Israel, incluindo o ataque em 1º de abril ao consulado iraniano, que Teerã atribuiu a Israel. Devido aos ataques, os espaços aéreos foram fechados em todo o Oriente Médio no sábado. A Jordânia, o Líbano e o Iraque, três países localizados na provável trajetória de voo destes drones, fecharam o seu espaço aéreo. O Irã e Israel também fecharam os seus para todos, exceto aeronaves militares. O Conselho de Segurança da ONU se reunirá, neste domingo (14/3), para uma reunião de emergência sobre o ataque do Irã a Israel, disse sua presidente, Vanessa Frazier. Desdobramento da guerra em Gaza Entre os inúmeros desdobramentos da guerra de Israel contra o Hamas na Faixa Gaza, a intensificação da inimizade entre Israel e o Irã é considerada a mais explosiva, escreve a correspondente internacional da BBC Lyse Doucet. Os países têm uma grande rivalidade há anos, o que já deixou um grande número de mortos, muitas vezes em ações secretas em que nenhum dos governos admite sua responsabilidade. Desde que a guerra em Gaza eclodiu há seis meses, Israel intensificou os seus movimentos contra o Irã, não apenas atacando o fornecimento de armas e infraestruturas na Síria, mas assassinando altos comandantes do Corpo da Guarda Revolucionária Islâmica (IRGC) do Irã e do Hezbollah (organização política e paramilitar fundamentalista islâmica, criada no Irã e presente no Líbano). O Irã então apreendeu um navio comercial com ligações a Israel na manhã de sábado (13/4), mas analistas já afirmavam que era pouco provável que Teerã considerasse esta uma \"resposta apropriada\" aos últimos atos de Israel. O especialista israelense Raz Zimmt, pesquisador sênior do Instituto de Segurança Nacional em Tel Aviv, alertou que o Irã agiria com força. \"A paciência dos iranianos esgotou-se diante dos reveses atribuídos a Israel\", disse o pesquisador em rede social. Origem da Rivalidade Israel e Irã estão há anos em uma rivalidade sangrenta que virou uma das principais fontes de instabilidade no Oriente Médio e cuja intensidade varia de acordo com o momento geopolítico. As relações entre Israel e o Irã foram bastante cordiais até 1979, quando a chamada Revolução Islâmica dos aiatolás conquistou o poder em Teerã. E embora tenha se oposto ao plano de fatiamento da Palestina que resultou na criação do Estado de Israel em 1948, o Irã foi o segundo país islâmico a reconhecer Israel, depois do Egito. O Irã era uma monarquia na qual reinavam os xás da dinastia Pahlavi e um dos principais aliados dos Estados Unidos no Oriente Médio. Assim, o fundador de Israel e seu primeiro chefe de governo, David Ben-Gurion, procurou e conseguiu a amizade iraniana como forma de combater a rejeição do novo Estado judeu de seus vizinhos árabes. Mas a Revolução de Ruhollah Khomeini, em 1979, derrubou o xá e impôs uma república islâmica que se apresentava como defensora dos oprimidos e tinha como principais marcas a rejeição ao \"imperialismo\" americano e a Israel. Teerã então passou a considerar que Israel não tem o direito de existir. Os governantes iranianos consideram o país o \"pequeno Satanás\", o aliado no Oriente Médio dos Estados Unidos, que chamam de \"grande Satanás\". Já Israel acusa o Irã de \"financiar grupos terroristas\" e de realizar ataques contra seus interesses, movidos pelo antissemitismo dos aiatolás. '"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TEXT_FILE = \"noticia.txt\"  # ou /content/noticia.txt no colab\n",
        "\n",
        "text = open(TEXT_FILE, \"r\")\n",
        "\n",
        "text = text.read()\n",
        "\n",
        "text = re.sub(r\"\\s+\", \" \", text)  # remove espaços em branco\n",
        "\n",
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Tokenizando o texto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "l13Dcq14Qssm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens:\n",
            "Token 0: Pela\n",
            "Token 1: primeira\n",
            "Token 2: vez\n",
            "Token 3: ,\n",
            "Token 4: o\n",
            "Token 5: Irã\n",
            "Token 6: realizou\n",
            "Token 7: ataques\n",
            "Token 8: diretos\n",
            "Token 9: contra\n",
            "Token 10: o\n",
            "Token 11: território\n",
            "Token 12: de\n",
            "Token 13: Israel\n",
            "Token 14: neste\n",
            "Token 15: sábado\n",
            "Token 16: (\n",
            "Token 17: 13/4\n",
            "Token 18: )\n",
            "Token 19: .\n",
            "Token 20: No\n",
            "Token 21: meio\n",
            "Token 22: da\n",
            "Token 23: noite\n",
            "Token 24: de\n",
            "Token 25: sábado\n",
            "Token 26: ,\n",
            "Token 27: alertas\n",
            "Token 28: de\n",
            "Token 29: ataque\n",
            "Token 30: aéreo\n",
            "Token 31: dispararam\n",
            "Token 32: em\n",
            "Token 33: Israel\n",
            "Token 34: .\n",
            "Token 35: Os\n",
            "Token 36: residentes\n",
            "Token 37: procuraram\n",
            "Token 38: abrigo\n",
            "Token 39: enquanto\n",
            "Token 40: explosões\n",
            "Token 41: eram\n",
            "Token 42: ouvidas\n",
            "Token 43: e\n",
            "Token 44: as\n",
            "Token 45: defesas\n",
            "Token 46: aéreas\n",
            "Token 47: eram\n",
            "Token 48: ativadas\n",
            "Token 49: .\n",
            "Token 50: As\n",
            "Token 51: interceptações\n",
            "Token 52: iluminaram\n",
            "Token 53: o\n",
            "Token 54: céu\n",
            "Token 55: noturno\n",
            "Token 56: em\n",
            "Token 57: vários\n",
            "Token 58: lugares\n",
            "Token 59: do\n",
            "Token 60: país\n",
            "Token 61: ,\n",
            "Token 62: enquanto\n",
            "Token 63: muitos\n",
            "Token 64: drones\n",
            "Token 65: e\n",
            "Token 66: mísseis\n",
            "Token 67: foram\n",
            "Token 68: abatidos\n",
            "Token 69: pelos\n",
            "Token 70: aliados\n",
            "Token 71: de\n",
            "Token 72: Israel\n",
            "Token 73: antes\n",
            "Token 74: de\n",
            "Token 75: chegarem\n",
            "Token 76: ao\n",
            "Token 77: território\n",
            "Token 78: israelense\n",
            "Token 79: .\n",
            "Token 80: Pelo\n",
            "Token 81: menos\n",
            "Token 82: nove\n",
            "Token 83: países\n",
            "Token 84: estiveram\n",
            "Token 85: envolvidos\n",
            "Token 86: na\n",
            "Token 87: escalada\n",
            "Token 88: militar\n",
            "Token 89: –\n",
            "Token 90: com\n",
            "Token 91: projéteis\n",
            "Token 92: disparados\n",
            "Token 93: do\n",
            "Token 94: Irã\n",
            "Token 95: ,\n",
            "Token 96: Iraque\n",
            "Token 97: ,\n",
            "Token 98: Síria\n",
            "Token 99: e\n",
            "Token 100: Iêmen\n",
            "Token 101: e\n",
            "Token 102: abatidos\n",
            "Token 103: por\n",
            "Token 104: Israel\n",
            "Token 105: ,\n",
            "Token 106: pelos\n",
            "Token 107: EUA\n",
            "Token 108: e\n",
            "Token 109: pela\n",
            "Token 110: França\n",
            "Token 111: ,\n",
            "Token 112: bem\n",
            "Token 113: como\n",
            "Token 114: pela\n",
            "Token 115: Jordânia\n",
            "Token 116: .\n",
            "Token 117: Uma\n",
            "Token 118: represália\n",
            "Token 119: era\n",
            "Token 120: esperada\n",
            "Token 121: .\n",
            "Token 122: O\n",
            "Token 123: Irã\n",
            "Token 124: havia\n",
            "Token 125: prometido\n",
            "Token 126: retaliar\n",
            "Token 127: depois\n",
            "Token 128: de\n",
            "Token 129: um\n",
            "Token 130: ataque\n",
            "Token 131: ao\n",
            "Token 132: seu\n",
            "Token 133: consulado\n",
            "Token 134: na\n",
            "Token 135: Síria\n",
            "Token 136: ,\n",
            "Token 137: no\n",
            "Token 138: dia\n",
            "Token 139: 1º\n",
            "Token 140: de\n",
            "Token 141: abril\n",
            "Token 142: ,\n",
            "Token 143: que\n",
            "Token 144: atribuiu\n",
            "Token 145: a\n",
            "Token 146: Israel\n",
            "Token 147: (\n",
            "Token 148: embora\n",
            "Token 149: Israel\n",
            "Token 150: não\n",
            "Token 151: tenha\n",
            "Token 152: confirmado\n",
            "Token 153: ser\n",
            "Token 154: o\n",
            "Token 155: autor\n",
            "Token 156: )\n",
            "Token 157: .\n",
            "Token 158: Permanecer\n",
            "Token 159: alerta\n",
            "Token 160: As\n",
            "Token 161: forças\n",
            "Token 162: israelenses\n",
            "Token 163: estão\n",
            "Token 164: em\n",
            "Token 165: alerta\n",
            "Token 166: máximo\n",
            "Token 167: e\n",
            "Token 168: \"\n",
            "Token 169: monitorando\n",
            "Token 170: todos\n",
            "Token 171: os\n",
            "Token 172: alvos\n",
            "Token 173: \"\n",
            "Token 174: .\n",
            "Token 175: Após\n",
            "Token 176: o\n",
            "Token 177: ataque\n",
            "Token 178: ,\n",
            "Token 179: o\n",
            "Token 180: primeiro-ministro\n",
            "Token 181: de\n",
            "Token 182: Israel\n",
            "Token 183: ,\n",
            "Token 184: Benjamin\n",
            "Token 185: Netanyahu\n",
            "Token 186: ,\n",
            "Token 187: afirmou\n",
            "Token 188: que\n",
            "Token 189: \"\n",
            "Token 190: juntos\n",
            "Token 191: venceremos\n",
            "Token 192: \"\n",
            "Token 193: ,\n",
            "Token 194: mas\n",
            "Token 195: não\n",
            "Token 196: está\n",
            "Token 197: claro\n",
            "Token 198: qual\n",
            "Token 199: será\n",
            "Token 200: a\n",
            "Token 201: resposta\n",
            "Token 202: de\n",
            "Token 203: Israel\n",
            "Token 204: .\n",
            "Token 205: O\n",
            "Token 206: presidente\n",
            "Token 207: Biden\n",
            "Token 208: disse\n",
            "Token 209: ter\n",
            "Token 210: reafirmado\n",
            "Token 211: \"\n",
            "Token 212: o\n",
            "Token 213: firme\n",
            "Token 214: compromisso\n",
            "Token 215: da\n",
            "Token 216: América\n",
            "Token 217: com\n",
            "Token 218: a\n",
            "Token 219: segurança\n",
            "Token 220: de\n",
            "Token 221: Israel\n",
            "Token 222: \"\n",
            "Token 223: .\n",
            "Token 224: O\n",
            "Token 225: porta-voz\n",
            "Token 226: das\n",
            "Token 227: Forças\n",
            "Token 228: de\n",
            "Token 229: Defesa\n",
            "Token 230: de\n",
            "Token 231: Israel\n",
            "Token 232: ,\n",
            "Token 233: contra-almirante\n",
            "Token 234: Daniel\n",
            "Token 235: Hagari\n",
            "Token 236: ,\n",
            "Token 237: disse\n",
            "Token 238: que\n",
            "Token 239: alguns\n",
            "Token 240: mísseis\n",
            "Token 241: iranianos\n",
            "Token 242: atingiram\n",
            "Token 243: o\n",
            "Token 244: interior\n",
            "Token 245: de\n",
            "Token 246: Israel\n",
            "Token 247: ,\n",
            "Token 248: causando\n",
            "Token 249: pequenos\n",
            "Token 250: danos\n",
            "Token 251: a\n",
            "Token 252: uma\n",
            "Token 253: base\n",
            "Token 254: militar\n",
            "Token 255: ,\n",
            "Token 256: mas\n",
            "Token 257: sem\n",
            "Token 258: vítimas\n",
            "Token 259: .\n",
            "Token 260: O\n",
            "Token 261: serviço\n",
            "Token 262: de\n",
            "Token 263: ambulância\n",
            "Token 264: de\n",
            "Token 265: Israel\n",
            "Token 266: disse\n",
            "Token 267: que\n",
            "Token 268: uma\n",
            "Token 269: menina\n",
            "Token 270: beduína\n",
            "Token 271: de\n",
            "Token 272: sete\n",
            "Token 273: anos\n",
            "Token 274: foi\n",
            "Token 275: ferida\n",
            "Token 276: por\n",
            "Token 277: estilhaços\n",
            "Token 278: de\n",
            "Token 279: destroços\n",
            "Token 280: na\n",
            "Token 281: região\n",
            "Token 282: sul\n",
            "Token 283: de\n",
            "Token 284: Arad\n",
            "Token 285: .\n",
            "Token 286: Hagari\n",
            "Token 287: disse\n",
            "Token 288: que\n",
            "Token 289: o\n",
            "Token 290: ataque\n",
            "Token 291: em\n",
            "Token 292: larga\n",
            "Token 293: escala\n",
            "Token 294: foi\n",
            "Token 295: uma\n",
            "Token 296: \"\n",
            "Token 297: grande\n",
            "Token 298: escalada\n",
            "Token 299: \"\n",
            "Token 300: e\n",
            "Token 301: disse\n",
            "Token 302: que\n",
            "Token 303: Israel\n",
            "Token 304: e\n",
            "Token 305: seus\n",
            "Token 306: aliados\n",
            "Token 307: operaram\n",
            "Token 308: com\n",
            "Token 309: força\n",
            "Token 310: total\n",
            "Token 311: para\n",
            "Token 312: defender\n",
            "Token 313: Israel\n",
            "Token 314: .\n",
            "Token 315: Ele\n",
            "Token 316: disse\n",
            "Token 317: que\n",
            "Token 318: o\n",
            "Token 319: Irã\n",
            "Token 320: disparou\n",
            "Token 321: mais\n",
            "Token 322: de\n",
            "Token 323: 300\n",
            "Token 324: projéteis\n",
            "Token 325: contra\n",
            "Token 326: Israel\n",
            "Token 327: durante\n",
            "Token 328: a\n",
            "Token 329: noite\n",
            "Token 330: ,\n",
            "Token 331: 99\n",
            "Token 332: %\n",
            "Token 333: dos\n",
            "Token 334: quais\n",
            "Token 335: foram\n",
            "Token 336: abatidos\n",
            "Token 337: .\n",
            "Token 338: Ele\n",
            "Token 339: acrescentou\n",
            "Token 340: que\n",
            "Token 341: alguns\n",
            "Token 342: dos\n",
            "Token 343: lançamentos\n",
            "Token 344: chegaram\n",
            "Token 345: do\n",
            "Token 346: Iraque\n",
            "Token 347: e\n",
            "Token 348: do\n",
            "Token 349: Iêmen\n",
            "Token 350: .\n",
            "Token 351: O\n",
            "Token 352: ministro\n",
            "Token 353: da\n",
            "Token 354: Defesa\n",
            "Token 355: de\n",
            "Token 356: Israel\n",
            "Token 357: ,\n",
            "Token 358: Yoav\n",
            "Token 359: Gallant\n",
            "Token 360: ,\n",
            "Token 361: disse\n",
            "Token 362: que\n",
            "Token 363: \"\n",
            "Token 364: muito\n",
            "Token 365: poucos\n",
            "Token 366: danos\n",
            "Token 367: foram\n",
            "Token 368: causados\n",
            "Token 369: \"\n",
            "Token 370: ,\n",
            "Token 371: mas\n",
            "Token 372: alertou\n",
            "Token 373: que\n",
            "Token 374: \"\n",
            "Token 375: a\n",
            "Token 376: campanha\n",
            "Token 377: ainda\n",
            "Token 378: não\n",
            "Token 379: terminou\n",
            "Token 380: \"\n",
            "Token 381: e\n",
            "Token 382: disse\n",
            "Token 383: que\n",
            "Token 384: Israel\n",
            "Token 385: deve\n",
            "Token 386: \"\n",
            "Token 387: permanecer\n",
            "Token 388: alerta\n",
            "Token 389: \"\n",
            "Token 390: .\n",
            "Token 391: Quase\n",
            "Token 392: todos\n",
            "Token 393: Ao\n",
            "Token 394: expressar\n",
            "Token 395: forte\n",
            "Token 396: condenação\n",
            "Token 397: pelo\n",
            "Token 398: ataque\n",
            "Token 399: ,\n",
            "Token 400: o\n",
            "Token 401: presidente\n",
            "Token 402: dos\n",
            "Token 403: Estados\n",
            "Token 404: Unidos\n",
            "Token 405: ,\n",
            "Token 406: Joe\n",
            "Token 407: Biden\n",
            "Token 408: ,\n",
            "Token 409: disse\n",
            "Token 410: que\n",
            "Token 411: os\n",
            "Token 412: EUA\n",
            "Token 413: ajudaram\n",
            "Token 414: Israel\n",
            "Token 415: \"\n",
            "Token 416: a\n",
            "Token 417: derrubar\n",
            "Token 418: quase\n",
            "Token 419: todos\n",
            "Token 420: \"\n",
            "Token 421: os\n",
            "Token 422: mísseis\n",
            "Token 423: e\n",
            "Token 424: drones\n",
            "Token 425: .\n",
            "Token 426: \"\n",
            "Token 427: O\n",
            "Token 428: Irã\n",
            "Token 429: e\n",
            "Token 430: os\n",
            "Token 431: seus\n",
            "Token 432: representantes\n",
            "Token 433: que\n",
            "Token 434: operam\n",
            "Token 435: a\n",
            "Token 436: partir\n",
            "Token 437: do\n",
            "Token 438: Iêmen\n",
            "Token 439: ,\n",
            "Token 440: Síria\n",
            "Token 441: e\n",
            "Token 442: Iraque\n",
            "Token 443: lançaram\n",
            "Token 444: um\n",
            "Token 445: ataque\n",
            "Token 446: aéreo\n",
            "Token 447: sem\n",
            "Token 448: precedentes\n",
            "Token 449: contra\n",
            "Token 450: instalações\n",
            "Token 451: militares\n",
            "Token 452: em\n",
            "Token 453: Israel\n",
            "Token 454: \"\n",
            "Token 455: ,\n",
            "Token 456: disse\n",
            "Token 457: Biden\n",
            "Token 458: .\n",
            "Token 459: Em\n",
            "Token 460: um\n",
            "Token 461: comunicado\n",
            "Token 462: oficial\n",
            "Token 463: ,\n",
            "Token 464: o\n",
            "Token 465: Irã\n",
            "Token 466: afirmou\n",
            "Token 467: que\n",
            "Token 468: o\n",
            "Token 469: ataque\n",
            "Token 470: foi\n",
            "Token 471: nomeado\n",
            "Token 472: \"\n",
            "Token 473: Operação\n",
            "Token 474: Promessa\n",
            "Token 475: Verdadeira\n",
            "Token 476: \"\n",
            "Token 477: e\n",
            "Token 478: disse\n",
            "Token 479: que\n",
            "Token 480: lançou\n",
            "Token 481: \"\n",
            "Token 482: dezenas\n",
            "Token 483: de\n",
            "Token 484: mísseis\n",
            "Token 485: e\n",
            "Token 486: drones\n",
            "Token 487: contra\n",
            "Token 488: alvos\n",
            "Token 489: específicos\n",
            "Token 490: \"\n",
            "Token 491: em\n",
            "Token 492: Israel\n",
            "Token 493: .\n",
            "Token 494: A\n",
            "Token 495: declaração\n",
            "Token 496: militar\n",
            "Token 497: do\n",
            "Token 498: Irã\n",
            "Token 499: diz\n",
            "Token 500: que\n",
            "Token 501: o\n",
            "Token 502: ataque\n",
            "Token 503: está\n",
            "Token 504: relacionado\n",
            "Token 505: a\n",
            "Token 506: \"\n",
            "Token 507: crimes\n",
            "Token 508: repetidos\n",
            "Token 509: \"\n",
            "Token 510: de\n",
            "Token 511: Israel\n",
            "Token 512: ,\n",
            "Token 513: incluindo\n",
            "Token 514: o\n",
            "Token 515: ataque\n",
            "Token 516: em\n",
            "Token 517: 1º\n",
            "Token 518: de\n",
            "Token 519: abril\n",
            "Token 520: ao\n",
            "Token 521: consulado\n",
            "Token 522: iraniano\n",
            "Token 523: ,\n",
            "Token 524: que\n",
            "Token 525: Teerã\n",
            "Token 526: atribuiu\n",
            "Token 527: a\n",
            "Token 528: Israel\n",
            "Token 529: .\n",
            "Token 530: Devido\n",
            "Token 531: aos\n",
            "Token 532: ataques\n",
            "Token 533: ,\n",
            "Token 534: os\n",
            "Token 535: espaços\n",
            "Token 536: aéreos\n",
            "Token 537: foram\n",
            "Token 538: fechados\n",
            "Token 539: em\n",
            "Token 540: todo\n",
            "Token 541: o\n",
            "Token 542: Oriente\n",
            "Token 543: Médio\n",
            "Token 544: no\n",
            "Token 545: sábado\n",
            "Token 546: .\n",
            "Token 547: A\n",
            "Token 548: Jordânia\n",
            "Token 549: ,\n",
            "Token 550: o\n",
            "Token 551: Líbano\n",
            "Token 552: e\n",
            "Token 553: o\n",
            "Token 554: Iraque\n",
            "Token 555: ,\n",
            "Token 556: três\n",
            "Token 557: países\n",
            "Token 558: localizados\n",
            "Token 559: na\n",
            "Token 560: provável\n",
            "Token 561: trajetória\n",
            "Token 562: de\n",
            "Token 563: voo\n",
            "Token 564: destes\n",
            "Token 565: drones\n",
            "Token 566: ,\n",
            "Token 567: fecharam\n",
            "Token 568: o\n",
            "Token 569: seu\n",
            "Token 570: espaço\n",
            "Token 571: aéreo\n",
            "Token 572: .\n",
            "Token 573: O\n",
            "Token 574: Irã\n",
            "Token 575: e\n",
            "Token 576: Israel\n",
            "Token 577: também\n",
            "Token 578: fecharam\n",
            "Token 579: os\n",
            "Token 580: seus\n",
            "Token 581: para\n",
            "Token 582: todos\n",
            "Token 583: ,\n",
            "Token 584: exceto\n",
            "Token 585: aeronaves\n",
            "Token 586: militares\n",
            "Token 587: .\n",
            "Token 588: O\n",
            "Token 589: Conselho\n",
            "Token 590: de\n",
            "Token 591: Segurança\n",
            "Token 592: da\n",
            "Token 593: ONU\n",
            "Token 594: se\n",
            "Token 595: reunirá\n",
            "Token 596: ,\n",
            "Token 597: neste\n",
            "Token 598: domingo\n",
            "Token 599: (\n",
            "Token 600: 14/3\n",
            "Token 601: )\n",
            "Token 602: ,\n",
            "Token 603: para\n",
            "Token 604: uma\n",
            "Token 605: reunião\n",
            "Token 606: de\n",
            "Token 607: emergência\n",
            "Token 608: sobre\n",
            "Token 609: o\n",
            "Token 610: ataque\n",
            "Token 611: do\n",
            "Token 612: Irã\n",
            "Token 613: a\n",
            "Token 614: Israel\n",
            "Token 615: ,\n",
            "Token 616: disse\n",
            "Token 617: sua\n",
            "Token 618: presidente\n",
            "Token 619: ,\n",
            "Token 620: Vanessa\n",
            "Token 621: Frazier\n",
            "Token 622: .\n",
            "Token 623: Desdobramento\n",
            "Token 624: da\n",
            "Token 625: guerra\n",
            "Token 626: em\n",
            "Token 627: Gaza\n",
            "Token 628: Entre\n",
            "Token 629: os\n",
            "Token 630: inúmeros\n",
            "Token 631: desdobramentos\n",
            "Token 632: da\n",
            "Token 633: guerra\n",
            "Token 634: de\n",
            "Token 635: Israel\n",
            "Token 636: contra\n",
            "Token 637: o\n",
            "Token 638: Hamas\n",
            "Token 639: na\n",
            "Token 640: Faixa\n",
            "Token 641: Gaza\n",
            "Token 642: ,\n",
            "Token 643: a\n",
            "Token 644: intensificação\n",
            "Token 645: da\n",
            "Token 646: inimizade\n",
            "Token 647: entre\n",
            "Token 648: Israel\n",
            "Token 649: e\n",
            "Token 650: o\n",
            "Token 651: Irã\n",
            "Token 652: é\n",
            "Token 653: considerada\n",
            "Token 654: a\n",
            "Token 655: mais\n",
            "Token 656: explosiva\n",
            "Token 657: ,\n",
            "Token 658: escreve\n",
            "Token 659: a\n",
            "Token 660: correspondente\n",
            "Token 661: internacional\n",
            "Token 662: da\n",
            "Token 663: BBC\n",
            "Token 664: Lyse\n",
            "Token 665: Doucet\n",
            "Token 666: .\n",
            "Token 667: Os\n",
            "Token 668: países\n",
            "Token 669: têm\n",
            "Token 670: uma\n",
            "Token 671: grande\n",
            "Token 672: rivalidade\n",
            "Token 673: há\n",
            "Token 674: anos\n",
            "Token 675: ,\n",
            "Token 676: o\n",
            "Token 677: que\n",
            "Token 678: já\n",
            "Token 679: deixou\n",
            "Token 680: um\n",
            "Token 681: grande\n",
            "Token 682: número\n",
            "Token 683: de\n",
            "Token 684: mortos\n",
            "Token 685: ,\n",
            "Token 686: muitas\n",
            "Token 687: vezes\n",
            "Token 688: em\n",
            "Token 689: ações\n",
            "Token 690: secretas\n",
            "Token 691: em\n",
            "Token 692: que\n",
            "Token 693: nenhum\n",
            "Token 694: dos\n",
            "Token 695: governos\n",
            "Token 696: admite\n",
            "Token 697: sua\n",
            "Token 698: responsabilidade\n",
            "Token 699: .\n",
            "Token 700: Desde\n",
            "Token 701: que\n",
            "Token 702: a\n",
            "Token 703: guerra\n",
            "Token 704: em\n",
            "Token 705: Gaza\n",
            "Token 706: eclodiu\n",
            "Token 707: há\n",
            "Token 708: seis\n",
            "Token 709: meses\n",
            "Token 710: ,\n",
            "Token 711: Israel\n",
            "Token 712: intensificou\n",
            "Token 713: os\n",
            "Token 714: seus\n",
            "Token 715: movimentos\n",
            "Token 716: contra\n",
            "Token 717: o\n",
            "Token 718: Irã\n",
            "Token 719: ,\n",
            "Token 720: não\n",
            "Token 721: apenas\n",
            "Token 722: atacando\n",
            "Token 723: o\n",
            "Token 724: fornecimento\n",
            "Token 725: de\n",
            "Token 726: armas\n",
            "Token 727: e\n",
            "Token 728: infraestruturas\n",
            "Token 729: na\n",
            "Token 730: Síria\n",
            "Token 731: ,\n",
            "Token 732: mas\n",
            "Token 733: assassinando\n",
            "Token 734: altos\n",
            "Token 735: comandantes\n",
            "Token 736: do\n",
            "Token 737: Corpo\n",
            "Token 738: da\n",
            "Token 739: Guarda\n",
            "Token 740: Revolucionária\n",
            "Token 741: Islâmica\n",
            "Token 742: (\n",
            "Token 743: IRGC\n",
            "Token 744: )\n",
            "Token 745: do\n",
            "Token 746: Irã\n",
            "Token 747: e\n",
            "Token 748: do\n",
            "Token 749: Hezbollah\n",
            "Token 750: (\n",
            "Token 751: organização\n",
            "Token 752: política\n",
            "Token 753: e\n",
            "Token 754: paramilitar\n",
            "Token 755: fundamentalista\n",
            "Token 756: islâmica\n",
            "Token 757: ,\n",
            "Token 758: criada\n",
            "Token 759: no\n",
            "Token 760: Irã\n",
            "Token 761: e\n",
            "Token 762: presente\n",
            "Token 763: no\n",
            "Token 764: Líbano\n",
            "Token 765: )\n",
            "Token 766: .\n",
            "Token 767: O\n",
            "Token 768: Irã\n",
            "Token 769: então\n",
            "Token 770: apreendeu\n",
            "Token 771: um\n",
            "Token 772: navio\n",
            "Token 773: comercial\n",
            "Token 774: com\n",
            "Token 775: ligações\n",
            "Token 776: a\n",
            "Token 777: Israel\n",
            "Token 778: na\n",
            "Token 779: manhã\n",
            "Token 780: de\n",
            "Token 781: sábado\n",
            "Token 782: (\n",
            "Token 783: 13/4\n",
            "Token 784: )\n",
            "Token 785: ,\n",
            "Token 786: mas\n",
            "Token 787: analistas\n",
            "Token 788: já\n",
            "Token 789: afirmavam\n",
            "Token 790: que\n",
            "Token 791: era\n",
            "Token 792: pouco\n",
            "Token 793: provável\n",
            "Token 794: que\n",
            "Token 795: Teerã\n",
            "Token 796: considerasse\n",
            "Token 797: esta\n",
            "Token 798: uma\n",
            "Token 799: \"\n",
            "Token 800: resposta\n",
            "Token 801: apropriada\n",
            "Token 802: \"\n",
            "Token 803: aos\n",
            "Token 804: últimos\n",
            "Token 805: atos\n",
            "Token 806: de\n",
            "Token 807: Israel\n",
            "Token 808: .\n",
            "Token 809: O\n",
            "Token 810: especialista\n",
            "Token 811: israelense\n",
            "Token 812: Raz\n",
            "Token 813: Zimmt\n",
            "Token 814: ,\n",
            "Token 815: pesquisador\n",
            "Token 816: sênior\n",
            "Token 817: do\n",
            "Token 818: Instituto\n",
            "Token 819: de\n",
            "Token 820: Segurança\n",
            "Token 821: Nacional\n",
            "Token 822: em\n",
            "Token 823: Tel\n",
            "Token 824: Aviv\n",
            "Token 825: ,\n",
            "Token 826: alertou\n",
            "Token 827: que\n",
            "Token 828: o\n",
            "Token 829: Irã\n",
            "Token 830: agiria\n",
            "Token 831: com\n",
            "Token 832: força\n",
            "Token 833: .\n",
            "Token 834: \"\n",
            "Token 835: A\n",
            "Token 836: paciência\n",
            "Token 837: dos\n",
            "Token 838: iranianos\n",
            "Token 839: esgotou-se\n",
            "Token 840: diante\n",
            "Token 841: dos\n",
            "Token 842: reveses\n",
            "Token 843: atribuídos\n",
            "Token 844: a\n",
            "Token 845: Israel\n",
            "Token 846: \"\n",
            "Token 847: ,\n",
            "Token 848: disse\n",
            "Token 849: o\n",
            "Token 850: pesquisador\n",
            "Token 851: em\n",
            "Token 852: rede\n",
            "Token 853: social\n",
            "Token 854: .\n",
            "Token 855: Origem\n",
            "Token 856: da\n",
            "Token 857: Rivalidade\n",
            "Token 858: Israel\n",
            "Token 859: e\n",
            "Token 860: Irã\n",
            "Token 861: estão\n",
            "Token 862: há\n",
            "Token 863: anos\n",
            "Token 864: em\n",
            "Token 865: uma\n",
            "Token 866: rivalidade\n",
            "Token 867: sangrenta\n",
            "Token 868: que\n",
            "Token 869: virou\n",
            "Token 870: uma\n",
            "Token 871: das\n",
            "Token 872: principais\n",
            "Token 873: fontes\n",
            "Token 874: de\n",
            "Token 875: instabilidade\n",
            "Token 876: no\n",
            "Token 877: Oriente\n",
            "Token 878: Médio\n",
            "Token 879: e\n",
            "Token 880: cuja\n",
            "Token 881: intensidade\n",
            "Token 882: varia\n",
            "Token 883: de\n",
            "Token 884: acordo\n",
            "Token 885: com\n",
            "Token 886: o\n",
            "Token 887: momento\n",
            "Token 888: geopolítico\n",
            "Token 889: .\n",
            "Token 890: As\n",
            "Token 891: relações\n",
            "Token 892: entre\n",
            "Token 893: Israel\n",
            "Token 894: e\n",
            "Token 895: o\n",
            "Token 896: Irã\n",
            "Token 897: foram\n",
            "Token 898: bastante\n",
            "Token 899: cordiais\n",
            "Token 900: até\n",
            "Token 901: 1979\n",
            "Token 902: ,\n",
            "Token 903: quando\n",
            "Token 904: a\n",
            "Token 905: chamada\n",
            "Token 906: Revolução\n",
            "Token 907: Islâmica\n",
            "Token 908: dos\n",
            "Token 909: aiatolás\n",
            "Token 910: conquistou\n",
            "Token 911: o\n",
            "Token 912: poder\n",
            "Token 913: em\n",
            "Token 914: Teerã\n",
            "Token 915: .\n",
            "Token 916: E\n",
            "Token 917: embora\n",
            "Token 918: tenha\n",
            "Token 919: se\n",
            "Token 920: oposto\n",
            "Token 921: ao\n",
            "Token 922: plano\n",
            "Token 923: de\n",
            "Token 924: fatiamento\n",
            "Token 925: da\n",
            "Token 926: Palestina\n",
            "Token 927: que\n",
            "Token 928: resultou\n",
            "Token 929: na\n",
            "Token 930: criação\n",
            "Token 931: do\n",
            "Token 932: Estado\n",
            "Token 933: de\n",
            "Token 934: Israel\n",
            "Token 935: em\n",
            "Token 936: 1948\n",
            "Token 937: ,\n",
            "Token 938: o\n",
            "Token 939: Irã\n",
            "Token 940: foi\n",
            "Token 941: o\n",
            "Token 942: segundo\n",
            "Token 943: país\n",
            "Token 944: islâmico\n",
            "Token 945: a\n",
            "Token 946: reconhecer\n",
            "Token 947: Israel\n",
            "Token 948: ,\n",
            "Token 949: depois\n",
            "Token 950: do\n",
            "Token 951: Egito\n",
            "Token 952: .\n",
            "Token 953: O\n",
            "Token 954: Irã\n",
            "Token 955: era\n",
            "Token 956: uma\n",
            "Token 957: monarquia\n",
            "Token 958: na\n",
            "Token 959: qual\n",
            "Token 960: reinavam\n",
            "Token 961: os\n",
            "Token 962: xás\n",
            "Token 963: da\n",
            "Token 964: dinastia\n",
            "Token 965: Pahlavi\n",
            "Token 966: e\n",
            "Token 967: um\n",
            "Token 968: dos\n",
            "Token 969: principais\n",
            "Token 970: aliados\n",
            "Token 971: dos\n",
            "Token 972: Estados\n",
            "Token 973: Unidos\n",
            "Token 974: no\n",
            "Token 975: Oriente\n",
            "Token 976: Médio\n",
            "Token 977: .\n",
            "Token 978: Assim\n",
            "Token 979: ,\n",
            "Token 980: o\n",
            "Token 981: fundador\n",
            "Token 982: de\n",
            "Token 983: Israel\n",
            "Token 984: e\n",
            "Token 985: seu\n",
            "Token 986: primeiro\n",
            "Token 987: chefe\n",
            "Token 988: de\n",
            "Token 989: governo\n",
            "Token 990: ,\n",
            "Token 991: David\n",
            "Token 992: Ben-Gurion\n",
            "Token 993: ,\n",
            "Token 994: procurou\n",
            "Token 995: e\n",
            "Token 996: conseguiu\n",
            "Token 997: a\n",
            "Token 998: amizade\n",
            "Token 999: iraniana\n",
            "Token 1000: como\n",
            "Token 1001: forma\n",
            "Token 1002: de\n",
            "Token 1003: combater\n",
            "Token 1004: a\n",
            "Token 1005: rejeição\n",
            "Token 1006: do\n",
            "Token 1007: novo\n",
            "Token 1008: Estado\n",
            "Token 1009: judeu\n",
            "Token 1010: de\n",
            "Token 1011: seus\n",
            "Token 1012: vizinhos\n",
            "Token 1013: árabes\n",
            "Token 1014: .\n",
            "Token 1015: Mas\n",
            "Token 1016: a\n",
            "Token 1017: Revolução\n",
            "Token 1018: de\n",
            "Token 1019: Ruhollah\n",
            "Token 1020: Khomeini\n",
            "Token 1021: ,\n",
            "Token 1022: em\n",
            "Token 1023: 1979\n",
            "Token 1024: ,\n",
            "Token 1025: derrubou\n",
            "Token 1026: o\n",
            "Token 1027: xá\n",
            "Token 1028: e\n",
            "Token 1029: impôs\n",
            "Token 1030: uma\n",
            "Token 1031: república\n",
            "Token 1032: islâmica\n",
            "Token 1033: que\n",
            "Token 1034: se\n",
            "Token 1035: apresentava\n",
            "Token 1036: como\n",
            "Token 1037: defensora\n",
            "Token 1038: dos\n",
            "Token 1039: oprimidos\n",
            "Token 1040: e\n",
            "Token 1041: tinha\n",
            "Token 1042: como\n",
            "Token 1043: principais\n",
            "Token 1044: marcas\n",
            "Token 1045: a\n",
            "Token 1046: rejeição\n",
            "Token 1047: ao\n",
            "Token 1048: \"\n",
            "Token 1049: imperialismo\n",
            "Token 1050: \"\n",
            "Token 1051: americano\n",
            "Token 1052: e\n",
            "Token 1053: a\n",
            "Token 1054: Israel\n",
            "Token 1055: .\n",
            "Token 1056: Teerã\n",
            "Token 1057: então\n",
            "Token 1058: passou\n",
            "Token 1059: a\n",
            "Token 1060: considerar\n",
            "Token 1061: que\n",
            "Token 1062: Israel\n",
            "Token 1063: não\n",
            "Token 1064: tem\n",
            "Token 1065: o\n",
            "Token 1066: direito\n",
            "Token 1067: de\n",
            "Token 1068: existir\n",
            "Token 1069: .\n",
            "Token 1070: Os\n",
            "Token 1071: governantes\n",
            "Token 1072: iranianos\n",
            "Token 1073: consideram\n",
            "Token 1074: o\n",
            "Token 1075: país\n",
            "Token 1076: o\n",
            "Token 1077: \"\n",
            "Token 1078: pequeno\n",
            "Token 1079: Satanás\n",
            "Token 1080: \"\n",
            "Token 1081: ,\n",
            "Token 1082: o\n",
            "Token 1083: aliado\n",
            "Token 1084: no\n",
            "Token 1085: Oriente\n",
            "Token 1086: Médio\n",
            "Token 1087: dos\n",
            "Token 1088: Estados\n",
            "Token 1089: Unidos\n",
            "Token 1090: ,\n",
            "Token 1091: que\n",
            "Token 1092: chamam\n",
            "Token 1093: de\n",
            "Token 1094: \"\n",
            "Token 1095: grande\n",
            "Token 1096: Satanás\n",
            "Token 1097: \"\n",
            "Token 1098: .\n",
            "Token 1099: Já\n",
            "Token 1100: Israel\n",
            "Token 1101: acusa\n",
            "Token 1102: o\n",
            "Token 1103: Irã\n",
            "Token 1104: de\n",
            "Token 1105: \"\n",
            "Token 1106: financiar\n",
            "Token 1107: grupos\n",
            "Token 1108: terroristas\n",
            "Token 1109: \"\n",
            "Token 1110: e\n",
            "Token 1111: de\n",
            "Token 1112: realizar\n",
            "Token 1113: ataques\n",
            "Token 1114: contra\n",
            "Token 1115: seus\n",
            "Token 1116: interesses\n",
            "Token 1117: ,\n",
            "Token 1118: movidos\n",
            "Token 1119: pelo\n",
            "Token 1120: antissemitismo\n",
            "Token 1121: dos\n",
            "Token 1122: aiatolás\n",
            "Token 1123: .\n"
          ]
        }
      ],
      "source": [
        "# Carregar o modelo para o idioma português\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "# Tokenizar o texto\n",
        "doc = nlp(text)\n",
        "\n",
        "\n",
        "print(\"Tokens:\")\n",
        "\n",
        "for index, token in enumerate(doc):\n",
        "    print(f\"Token {index}: {token.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Identificando as entidades nomeadas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOE7MHl_SPX3",
        "outputId": "0a22a4e7-e32e-4ec3-aaaa-d64dd5ebd333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entidades:\n",
            "Entidade 0: Jordânia - LOC\n",
            "Entidade 1: ministro da Defesa de Israel - MISC\n",
            "Entidade 2: Líbano - LOC\n",
            "Entidade 3: Palestina - LOC\n",
            "Entidade 4: Estados Unidos - LOC\n",
            "Entidade 5: Teerã - LOC\n",
            "Entidade 6: Iêmen - LOC\n",
            "Entidade 7: Forças de Defesa de Israel - ORG\n",
            "Entidade 8: Revolução de Ruhollah Khomeini - MISC\n",
            "Entidade 9: David Ben-Gurion - PER\n",
            "Entidade 10: Raz Zimmt - PER\n",
            "Entidade 11: Oriente Médio dos - ORG\n",
            "Entidade 12: Síria - LOC\n",
            "Entidade 13: Benjamin Netanyahu - PER\n",
            "Entidade 14: Instituto de Segurança Nacional - LOC\n",
            "Entidade 15: Faixa Gaza - LOC\n",
            "Entidade 16: Origem da Rivalidade Israel - MISC\n",
            "Entidade 17: Oriente Médio - LOC\n",
            "Entidade 18: Egito - LOC\n",
            "Entidade 19: Oriente Médio - ORG\n",
            "Entidade 20: Joe Biden - PER\n",
            "Entidade 21: Vanessa Frazier - PER\n",
            "Entidade 22: Hezbollah - ORG\n",
            "Entidade 23: Tel Aviv - LOC\n",
            "Entidade 24: Satanás - PER\n",
            "Entidade 25: América - LOC\n",
            "Entidade 26: Gaza - LOC\n",
            "Entidade 27: Lyse Doucet - PER\n",
            "Entidade 28: Daniel Hagari - PER\n",
            "Entidade 29: BBC - ORG\n",
            "Entidade 30: Biden - LOC\n",
            "Entidade 31: Corpo da Guarda Revolucionária Islâmica - ORG\n",
            "Entidade 32: guerra de Israel - MISC\n",
            "Entidade 33: Hagari - PER\n",
            "Entidade 34: Biden - PER\n",
            "Entidade 35: Estado de Israel - LOC\n",
            "Entidade 36: Iraque - LOC\n",
            "Entidade 37: Estado - LOC\n",
            "Entidade 38: Hamas - ORG\n",
            "Entidade 39: IRGC - ORG\n",
            "Entidade 40: EUA - LOC\n",
            "Entidade 41: Arad - LOC\n",
            "Entidade 42: Irã - LOC\n",
            "Entidade 43: Operação Promessa Verdadeira - MISC\n",
            "Entidade 44: Israel - ORG\n",
            "Entidade 45: França - LOC\n",
            "Entidade 46: dinastia Pahlavi - PER\n",
            "Entidade 47: Conselho de Segurança - ORG\n",
            "Entidade 48: Israel - LOC\n",
            "Entidade 49: ONU - ORG\n",
            "Entidade 50: Revolução Islâmica dos aiatolás - ORG\n",
            "Entidade 51: Yoav Gallant - PER\n"
          ]
        }
      ],
      "source": [
        "ents = set([(ent.text, ent.label_) for ent in doc.ents])  # entidades únicas\n",
        "\n",
        "print(\"Entidades:\")\n",
        "\n",
        "for index, (name, label) in enumerate(ents):\n",
        "    print(f\"Entidade {index}: {name} - {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Análise de sentenças - POS Tagging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElnKbP-BSnOl",
        "outputId": "f016ac73-1a80-4eea-b705-a4bd9cafc9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentença 0: Pela primeira vez, o Irã realizou ataque...\n",
            "\tToken 0: Pela - POS: NOUN - DEP: obl\n",
            "\tToken 1: primeira - POS: ADP - DEP: case\n",
            "\tToken 2: vez - POS: NOUN - DEP: nmod\n",
            "\tToken 3: , - POS: PUNCT - DEP: punct\n",
            "\tToken 4: o - POS: DET - DEP: det\n",
            "\tToken 5: Irã - POS: PROPN - DEP: nsubj\n",
            "\tToken 6: realizou - POS: VERB - DEP: ROOT\n",
            "\tToken 7: ataques - POS: NOUN - DEP: amod\n",
            "\tToken 8: diretos - POS: NOUN - DEP: obj\n",
            "\tToken 9: contra - POS: ADP - DEP: case\n",
            "\tToken 10: o - POS: DET - DEP: det\n",
            "\tToken 11: território - POS: NOUN - DEP: obl\n",
            "\tToken 12: de - POS: ADP - DEP: case\n",
            "\tToken 13: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 14: neste - POS: ADP - DEP: case\n",
            "\tToken 15: sábado - POS: NOUN - DEP: nmod\n",
            "\tToken 16: ( - POS: PUNCT - DEP: punct\n",
            "\tToken 17: 13/4 - POS: NOUN - DEP: appos\n",
            "\tToken 18: ) - POS: PUNCT - DEP: punct\n",
            "\tToken 19: . - POS: PUNCT - DEP: punct\n",
            "Sentença 1: No meio da noite de sábado, alertas de a...\n",
            "\tToken 0: No - POS: ADP - DEP: case\n",
            "\tToken 1: meio - POS: NOUN - DEP: obl\n",
            "\tToken 2: da - POS: ADP - DEP: case\n",
            "\tToken 3: noite - POS: NOUN - DEP: nmod\n",
            "\tToken 4: de - POS: ADP - DEP: case\n",
            "\tToken 5: sábado - POS: NOUN - DEP: nmod\n",
            "\tToken 6: , - POS: PUNCT - DEP: punct\n",
            "\tToken 7: alertas - POS: NOUN - DEP: nsubj\n",
            "\tToken 8: de - POS: ADP - DEP: case\n",
            "\tToken 9: ataque - POS: NOUN - DEP: nmod\n",
            "\tToken 10: aéreo - POS: ADJ - DEP: amod\n",
            "\tToken 11: dispararam - POS: VERB - DEP: ROOT\n",
            "\tToken 12: em - POS: ADP - DEP: case\n",
            "\tToken 13: Israel - POS: PROPN - DEP: obl\n",
            "\tToken 14: . - POS: PUNCT - DEP: punct\n",
            "Sentença 2: Os residentes procuraram abrigo enquanto...\n",
            "\tToken 0: Os - POS: DET - DEP: det\n",
            "\tToken 1: residentes - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: procuraram - POS: VERB - DEP: ROOT\n",
            "\tToken 3: abrigo - POS: NOUN - DEP: obj\n",
            "\tToken 4: enquanto - POS: ADV - DEP: advmod\n",
            "\tToken 5: explosões - POS: NOUN - DEP: nsubj:pass\n",
            "\tToken 6: eram - POS: AUX - DEP: aux:pass\n",
            "\tToken 7: ouvidas - POS: VERB - DEP: advcl\n",
            "\tToken 8: e - POS: CCONJ - DEP: cc\n",
            "\tToken 9: as - POS: DET - DEP: det\n",
            "\tToken 10: defesas - POS: NOUN - DEP: conj\n",
            "\tToken 11: aéreas - POS: ADJ - DEP: amod\n",
            "\tToken 12: eram - POS: AUX - DEP: aux:pass\n",
            "\tToken 13: ativadas - POS: ADJ - DEP: conj\n",
            "\tToken 14: . - POS: PUNCT - DEP: punct\n",
            "Sentença 3: As interceptações iluminaram o céu notur...\n",
            "\tToken 0: As - POS: DET - DEP: det\n",
            "\tToken 1: interceptações - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: iluminaram - POS: VERB - DEP: ROOT\n",
            "\tToken 3: o - POS: DET - DEP: det\n",
            "\tToken 4: céu - POS: NOUN - DEP: obj\n",
            "\tToken 5: noturno - POS: ADJ - DEP: amod\n",
            "\tToken 6: em - POS: ADP - DEP: case\n",
            "\tToken 7: vários - POS: DET - DEP: det\n",
            "\tToken 8: lugares - POS: NOUN - DEP: obl\n",
            "\tToken 9: do - POS: ADP - DEP: case\n",
            "\tToken 10: país - POS: NOUN - DEP: nmod\n",
            "\tToken 11: , - POS: PUNCT - DEP: punct\n",
            "\tToken 12: enquanto - POS: ADV - DEP: advmod\n",
            "\tToken 13: muitos - POS: DET - DEP: det\n",
            "\tToken 14: drones - POS: NOUN - DEP: nsubj:pass\n",
            "\tToken 15: e - POS: CCONJ - DEP: cc\n",
            "\tToken 16: mísseis - POS: NOUN - DEP: conj\n",
            "\tToken 17: foram - POS: AUX - DEP: aux:pass\n",
            "\tToken 18: abatidos - POS: VERB - DEP: advcl\n",
            "\tToken 19: pelos - POS: ADP - DEP: case\n",
            "\tToken 20: aliados - POS: NOUN - DEP: obl:agent\n",
            "\tToken 21: de - POS: ADP - DEP: case\n",
            "\tToken 22: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 23: antes - POS: ADV - DEP: mark\n",
            "\tToken 24: de - POS: ADP - DEP: fixed\n",
            "\tToken 25: chegarem - POS: VERB - DEP: advcl\n",
            "\tToken 26: ao - POS: ADP - DEP: case\n",
            "\tToken 27: território - POS: NOUN - DEP: obl\n",
            "\tToken 28: israelense - POS: ADJ - DEP: amod\n",
            "\tToken 29: . - POS: PUNCT - DEP: punct\n",
            "Sentença 4: Pelo menos nove países estiveram envolvi...\n",
            "\tToken 0: Pelo - POS: ADP - DEP: case\n",
            "\tToken 1: menos - POS: NOUN - DEP: advmod\n",
            "\tToken 2: nove - POS: NUM - DEP: nummod\n",
            "\tToken 3: países - POS: NOUN - DEP: nsubj:pass\n",
            "\tToken 4: estiveram - POS: AUX - DEP: aux:pass\n",
            "\tToken 5: envolvidos - POS: VERB - DEP: ROOT\n",
            "\tToken 6: na - POS: ADP - DEP: case\n",
            "\tToken 7: escalada - POS: NOUN - DEP: obl\n",
            "\tToken 8: militar - POS: ADJ - DEP: amod\n",
            "\tToken 9: – - POS: PUNCT - DEP: dep\n",
            "\tToken 10: com - POS: ADP - DEP: case\n",
            "\tToken 11: projéteis - POS: ADJ - DEP: amod\n",
            "\tToken 12: disparados - POS: NOUN - DEP: obl\n",
            "\tToken 13: do - POS: ADP - DEP: case\n",
            "\tToken 14: Irã - POS: PROPN - DEP: nmod\n",
            "\tToken 15: , - POS: PUNCT - DEP: punct\n",
            "\tToken 16: Iraque - POS: PROPN - DEP: conj\n",
            "\tToken 17: , - POS: PUNCT - DEP: punct\n",
            "\tToken 18: Síria - POS: PROPN - DEP: conj\n",
            "\tToken 19: e - POS: CCONJ - DEP: cc\n",
            "\tToken 20: Iêmen - POS: PROPN - DEP: conj\n",
            "\tToken 21: e - POS: CCONJ - DEP: cc\n",
            "\tToken 22: abatidos - POS: VERB - DEP: conj\n",
            "\tToken 23: por - POS: ADP - DEP: case\n",
            "\tToken 24: Israel - POS: PROPN - DEP: obl:agent\n",
            "\tToken 25: , - POS: PUNCT - DEP: punct\n",
            "\tToken 26: pelos - POS: ADP - DEP: case\n",
            "\tToken 27: EUA - POS: PROPN - DEP: obl:agent\n",
            "\tToken 28: e - POS: CCONJ - DEP: cc\n",
            "\tToken 29: pela - POS: ADP - DEP: case\n",
            "\tToken 30: França - POS: PROPN - DEP: conj\n",
            "\tToken 31: , - POS: PUNCT - DEP: punct\n",
            "\tToken 32: bem - POS: ADP - DEP: cc\n",
            "\tToken 33: como - POS: ADV - DEP: fixed\n",
            "\tToken 34: pela - POS: ADP - DEP: case\n",
            "\tToken 35: Jordânia - POS: PROPN - DEP: obl\n",
            "\tToken 36: . - POS: PUNCT - DEP: punct\n",
            "Sentença 5: Uma represália era esperada....\n",
            "\tToken 0: Uma - POS: DET - DEP: det\n",
            "\tToken 1: represália - POS: NOUN - DEP: nsubj:pass\n",
            "\tToken 2: era - POS: AUX - DEP: aux:pass\n",
            "\tToken 3: esperada - POS: VERB - DEP: ROOT\n",
            "\tToken 4: . - POS: PUNCT - DEP: punct\n",
            "Sentença 6: O Irã havia prometido retaliar depois de...\n",
            "\tToken 0: O - POS: DET - DEP: det\n",
            "\tToken 1: Irã - POS: PROPN - DEP: nsubj\n",
            "\tToken 2: havia - POS: AUX - DEP: aux\n",
            "\tToken 3: prometido - POS: VERB - DEP: ROOT\n",
            "\tToken 4: retaliar - POS: VERB - DEP: xcomp\n",
            "\tToken 5: depois - POS: ADV - DEP: advmod\n",
            "\tToken 6: de - POS: ADP - DEP: case\n",
            "\tToken 7: um - POS: DET - DEP: det\n",
            "\tToken 8: ataque - POS: NOUN - DEP: obl\n",
            "\tToken 9: ao - POS: ADP - DEP: case\n",
            "\tToken 10: seu - POS: DET - DEP: det\n",
            "\tToken 11: consulado - POS: NOUN - DEP: nmod\n",
            "\tToken 12: na - POS: ADP - DEP: case\n",
            "\tToken 13: Síria - POS: PROPN - DEP: nmod\n",
            "\tToken 14: , - POS: PUNCT - DEP: punct\n",
            "\tToken 15: no - POS: ADP - DEP: case\n",
            "\tToken 16: dia - POS: NOUN - DEP: obl\n",
            "\tToken 17: 1º - POS: ADJ - DEP: amod\n",
            "\tToken 18: de - POS: ADP - DEP: case\n",
            "\tToken 19: abril - POS: NOUN - DEP: nmod\n",
            "\tToken 20: , - POS: PUNCT - DEP: punct\n",
            "\tToken 21: que - POS: PRON - DEP: nsubj\n",
            "\tToken 22: atribuiu - POS: VERB - DEP: acl:relcl\n",
            "\tToken 23: a - POS: ADP - DEP: case\n",
            "\tToken 24: Israel - POS: PROPN - DEP: obj\n",
            "\tToken 25: ( - POS: PUNCT - DEP: punct\n",
            "\tToken 26: embora - POS: SCONJ - DEP: mark\n",
            "\tToken 27: Israel - POS: PROPN - DEP: nsubj\n",
            "\tToken 28: não - POS: ADV - DEP: advmod\n",
            "\tToken 29: tenha - POS: AUX - DEP: aux\n",
            "\tToken 30: confirmado - POS: VERB - DEP: advcl\n",
            "\tToken 31: ser - POS: AUX - DEP: cop\n",
            "\tToken 32: o - POS: DET - DEP: det\n",
            "\tToken 33: autor - POS: NOUN - DEP: xcomp\n",
            "\tToken 34: ) - POS: PUNCT - DEP: punct\n",
            "\tToken 35: . - POS: PUNCT - DEP: punct\n",
            "Sentença 7: Permanecer alerta...\n",
            "\tToken 0: Permanecer - POS: PROPN - DEP: nsubj\n",
            "\tToken 1: alerta - POS: VERB - DEP: ROOT\n",
            "Sentença 8: As forças israelenses estão em alerta má...\n",
            "\tToken 0: As - POS: DET - DEP: det\n",
            "\tToken 1: forças - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: israelenses - POS: ADJ - DEP: amod\n",
            "\tToken 3: estão - POS: AUX - DEP: cop\n",
            "\tToken 4: em - POS: ADP - DEP: case\n",
            "\tToken 5: alerta - POS: NOUN - DEP: ROOT\n",
            "\tToken 6: máximo - POS: ADJ - DEP: amod\n",
            "\tToken 7: e - POS: CCONJ - DEP: cc\n",
            "\tToken 8: \" - POS: NUM - DEP: punct\n",
            "\tToken 9: monitorando - POS: VERB - DEP: conj\n",
            "\tToken 10: todos - POS: DET - DEP: det\n",
            "\tToken 11: os - POS: DET - DEP: fixed\n",
            "\tToken 12: alvos - POS: NOUN - DEP: obj\n",
            "\tToken 13: \" - POS: NUM - DEP: obj\n",
            "\tToken 14: . - POS: PUNCT - DEP: punct\n",
            "Sentença 9: Após o ataque, o primeiro-ministro de Is...\n",
            "\tToken 0: Após - POS: ADP - DEP: case\n",
            "\tToken 1: o - POS: DET - DEP: det\n",
            "\tToken 2: ataque - POS: NOUN - DEP: obl\n",
            "\tToken 3: , - POS: PUNCT - DEP: punct\n",
            "\tToken 4: o - POS: DET - DEP: det\n",
            "\tToken 5: primeiro-ministro - POS: NOUN - DEP: nsubj\n",
            "\tToken 6: de - POS: ADP - DEP: case\n",
            "\tToken 7: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 8: , - POS: PUNCT - DEP: punct\n",
            "\tToken 9: Benjamin - POS: PROPN - DEP: appos\n",
            "\tToken 10: Netanyahu - POS: PROPN - DEP: flat:name\n",
            "\tToken 11: , - POS: PUNCT - DEP: punct\n",
            "\tToken 12: afirmou - POS: VERB - DEP: ROOT\n",
            "\tToken 13: que - POS: SCONJ - DEP: mark\n",
            "\tToken 14: \" - POS: NUM - DEP: nummod\n",
            "\tToken 15: juntos - POS: NOUN - DEP: amod\n",
            "\tToken 16: venceremos - POS: VERB - DEP: ccomp\n",
            "\tToken 17: \" - POS: PUNCT - DEP: obj\n",
            "\tToken 18: , - POS: PUNCT - DEP: punct\n",
            "\tToken 19: mas - POS: CCONJ - DEP: cc\n",
            "\tToken 20: não - POS: ADV - DEP: advmod\n",
            "\tToken 21: está - POS: AUX - DEP: cop\n",
            "\tToken 22: claro - POS: ADJ - DEP: conj\n",
            "\tToken 23: qual - POS: PRON - DEP: csubj\n",
            "\tToken 24: será - POS: AUX - DEP: cop\n",
            "\tToken 25: a - POS: DET - DEP: det\n",
            "\tToken 26: resposta - POS: NOUN - DEP: nsubj\n",
            "\tToken 27: de - POS: ADP - DEP: case\n",
            "\tToken 28: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 29: . - POS: PUNCT - DEP: punct\n",
            "Sentença 10: O presidente Biden disse ter reafirmado ...\n",
            "\tToken 0: O - POS: DET - DEP: det\n",
            "\tToken 1: presidente - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: Biden - POS: PROPN - DEP: appos\n",
            "\tToken 3: disse - POS: VERB - DEP: ROOT\n",
            "\tToken 4: ter - POS: AUX - DEP: aux\n",
            "\tToken 5: reafirmado - POS: VERB - DEP: xcomp\n",
            "\tToken 6: \" - POS: PUNCT - DEP: obj\n",
            "\tToken 7: o - POS: DET - DEP: det\n",
            "\tToken 8: firme - POS: ADJ - DEP: amod\n",
            "\tToken 9: compromisso - POS: NOUN - DEP: obj\n",
            "\tToken 10: da - POS: ADP - DEP: case\n",
            "\tToken 11: América - POS: PROPN - DEP: nmod\n",
            "\tToken 12: com - POS: ADP - DEP: case\n",
            "\tToken 13: a - POS: DET - DEP: det\n",
            "\tToken 14: segurança - POS: NOUN - DEP: nmod\n",
            "\tToken 15: de - POS: ADP - DEP: case\n",
            "\tToken 16: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 17: \" - POS: PROPN - DEP: flat:name\n",
            "\tToken 18: . - POS: PUNCT - DEP: punct\n",
            "Sentença 11: O porta-voz das Forças de Defesa de Isra...\n",
            "\tToken 0: O - POS: DET - DEP: det\n",
            "\tToken 1: porta-voz - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: das - POS: ADP - DEP: case\n",
            "\tToken 3: Forças - POS: PROPN - DEP: nmod\n",
            "\tToken 4: de - POS: ADP - DEP: case\n",
            "\tToken 5: Defesa - POS: PROPN - DEP: nmod\n",
            "\tToken 6: de - POS: ADP - DEP: case\n",
            "\tToken 7: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 8: , - POS: PUNCT - DEP: punct\n",
            "\tToken 9: contra-almirante - POS: ADJ - DEP: appos\n",
            "\tToken 10: Daniel - POS: PROPN - DEP: appos\n",
            "\tToken 11: Hagari - POS: PROPN - DEP: flat:name\n",
            "\tToken 12: , - POS: PUNCT - DEP: punct\n",
            "\tToken 13: disse - POS: VERB - DEP: ROOT\n",
            "\tToken 14: que - POS: SCONJ - DEP: mark\n",
            "\tToken 15: alguns - POS: DET - DEP: det\n",
            "\tToken 16: mísseis - POS: NOUN - DEP: nsubj\n",
            "\tToken 17: iranianos - POS: ADJ - DEP: amod\n",
            "\tToken 18: atingiram - POS: VERB - DEP: ccomp\n",
            "\tToken 19: o - POS: DET - DEP: det\n",
            "\tToken 20: interior - POS: NOUN - DEP: obj\n",
            "\tToken 21: de - POS: ADP - DEP: case\n",
            "\tToken 22: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 23: , - POS: PUNCT - DEP: punct\n",
            "\tToken 24: causando - POS: VERB - DEP: advcl\n",
            "\tToken 25: pequenos - POS: ADJ - DEP: amod\n",
            "\tToken 26: danos - POS: NOUN - DEP: obj\n",
            "\tToken 27: a - POS: ADP - DEP: case\n",
            "\tToken 28: uma - POS: DET - DEP: det\n",
            "\tToken 29: base - POS: NOUN - DEP: iobj\n",
            "\tToken 30: militar - POS: ADJ - DEP: amod\n",
            "\tToken 31: , - POS: PUNCT - DEP: punct\n",
            "\tToken 32: mas - POS: CCONJ - DEP: cc\n",
            "\tToken 33: sem - POS: ADP - DEP: case\n",
            "\tToken 34: vítimas - POS: NOUN - DEP: conj\n",
            "\tToken 35: . - POS: PUNCT - DEP: punct\n",
            "Sentença 12: O serviço de ambulância de Israel disse ...\n",
            "\tToken 0: O - POS: DET - DEP: det\n",
            "\tToken 1: serviço - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: de - POS: ADP - DEP: case\n",
            "\tToken 3: ambulância - POS: NOUN - DEP: nmod\n",
            "\tToken 4: de - POS: ADP - DEP: case\n",
            "\tToken 5: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 6: disse - POS: VERB - DEP: ROOT\n",
            "\tToken 7: que - POS: SCONJ - DEP: mark\n",
            "\tToken 8: uma - POS: DET - DEP: det\n",
            "\tToken 9: menina - POS: NOUN - DEP: nsubj:pass\n",
            "\tToken 10: beduína - POS: ADJ - DEP: amod\n",
            "\tToken 11: de - POS: ADP - DEP: case\n",
            "\tToken 12: sete - POS: NUM - DEP: nummod\n",
            "\tToken 13: anos - POS: NOUN - DEP: nmod\n",
            "\tToken 14: foi - POS: AUX - DEP: aux:pass\n",
            "\tToken 15: ferida - POS: VERB - DEP: ccomp\n",
            "\tToken 16: por - POS: ADP - DEP: case\n",
            "\tToken 17: estilhaços - POS: NOUN - DEP: obl:agent\n",
            "\tToken 18: de - POS: ADP - DEP: case\n",
            "\tToken 19: destroços - POS: NOUN - DEP: nmod\n",
            "\tToken 20: na - POS: ADP - DEP: case\n",
            "\tToken 21: região - POS: NOUN - DEP: nmod\n",
            "\tToken 22: sul - POS: PROPN - DEP: flat:name\n",
            "\tToken 23: de - POS: ADP - DEP: case\n",
            "\tToken 24: Arad - POS: PROPN - DEP: nmod\n",
            "\tToken 25: . - POS: PUNCT - DEP: punct\n",
            "Sentença 13: Hagari disse que o ataque em larga escal...\n",
            "\tToken 0: Hagari - POS: PROPN - DEP: nsubj\n",
            "\tToken 1: disse - POS: VERB - DEP: ROOT\n",
            "\tToken 2: que - POS: SCONJ - DEP: mark\n",
            "\tToken 3: o - POS: DET - DEP: det\n",
            "\tToken 4: ataque - POS: NOUN - DEP: nsubj\n",
            "\tToken 5: em - POS: ADP - DEP: case\n",
            "\tToken 6: larga - POS: ADJ - DEP: amod\n",
            "\tToken 7: escala - POS: NOUN - DEP: nmod\n",
            "\tToken 8: foi - POS: AUX - DEP: cop\n",
            "\tToken 9: uma - POS: DET - DEP: det\n",
            "\tToken 10: \" - POS: NOUN - DEP: amod\n",
            "\tToken 11: grande - POS: ADJ - DEP: amod\n",
            "\tToken 12: escalada - POS: NOUN - DEP: ccomp\n",
            "\tToken 13: \" - POS: PUNCT - DEP: obj\n",
            "\tToken 14: e - POS: CCONJ - DEP: cc\n",
            "\tToken 15: disse - POS: VERB - DEP: conj\n",
            "\tToken 16: que - POS: SCONJ - DEP: mark\n",
            "\tToken 17: Israel - POS: PROPN - DEP: nsubj\n",
            "\tToken 18: e - POS: CCONJ - DEP: cc\n",
            "\tToken 19: seus - POS: DET - DEP: det\n",
            "\tToken 20: aliados - POS: NOUN - DEP: conj\n",
            "\tToken 21: operaram - POS: VERB - DEP: ccomp\n",
            "\tToken 22: com - POS: ADP - DEP: case\n",
            "\tToken 23: força - POS: NOUN - DEP: obl\n",
            "\tToken 24: total - POS: ADJ - DEP: amod\n",
            "\tToken 25: para - POS: SCONJ - DEP: mark\n",
            "\tToken 26: defender - POS: VERB - DEP: acl\n",
            "\tToken 27: Israel - POS: PROPN - DEP: obj\n",
            "\tToken 28: . - POS: PUNCT - DEP: punct\n",
            "Sentença 14: Ele disse que o Irã disparou mais de 300...\n",
            "\tToken 0: Ele - POS: PRON - DEP: nsubj\n",
            "\tToken 1: disse - POS: VERB - DEP: ROOT\n",
            "\tToken 2: que - POS: SCONJ - DEP: mark\n",
            "\tToken 3: o - POS: DET - DEP: det\n",
            "\tToken 4: Irã - POS: PROPN - DEP: nsubj\n",
            "\tToken 5: disparou - POS: VERB - DEP: ccomp\n",
            "\tToken 6: mais - POS: ADV - DEP: advmod\n",
            "\tToken 7: de - POS: ADP - DEP: fixed\n",
            "\tToken 8: 300 - POS: NUM - DEP: nummod\n",
            "\tToken 9: projéteis - POS: NOUN - DEP: obj\n",
            "\tToken 10: contra - POS: ADP - DEP: case\n",
            "\tToken 11: Israel - POS: PROPN - DEP: obl\n",
            "\tToken 12: durante - POS: ADP - DEP: case\n",
            "\tToken 13: a - POS: DET - DEP: det\n",
            "\tToken 14: noite - POS: NOUN - DEP: obl\n",
            "\tToken 15: , - POS: PUNCT - DEP: punct\n",
            "\tToken 16: 99 - POS: NUM - DEP: nummod\n",
            "\tToken 17: % - POS: SYM - DEP: nsubj:pass\n",
            "\tToken 18: dos - POS: ADP - DEP: case\n",
            "\tToken 19: quais - POS: PRON - DEP: nmod\n",
            "\tToken 20: foram - POS: AUX - DEP: aux:pass\n",
            "\tToken 21: abatidos - POS: VERB - DEP: conj\n",
            "\tToken 22: . - POS: PUNCT - DEP: punct\n",
            "Sentença 15: Ele acrescentou que alguns dos lançament...\n",
            "\tToken 0: Ele - POS: PRON - DEP: nsubj\n",
            "\tToken 1: acrescentou - POS: VERB - DEP: ROOT\n",
            "\tToken 2: que - POS: SCONJ - DEP: mark\n",
            "\tToken 3: alguns - POS: PRON - DEP: nsubj\n",
            "\tToken 4: dos - POS: ADP - DEP: case\n",
            "\tToken 5: lançamentos - POS: NOUN - DEP: nmod\n",
            "\tToken 6: chegaram - POS: VERB - DEP: ccomp\n",
            "\tToken 7: do - POS: ADP - DEP: case\n",
            "\tToken 8: Iraque - POS: PROPN - DEP: obl\n",
            "\tToken 9: e - POS: CCONJ - DEP: cc\n",
            "\tToken 10: do - POS: ADP - DEP: case\n",
            "\tToken 11: Iêmen - POS: PROPN - DEP: conj\n",
            "\tToken 12: . - POS: PUNCT - DEP: punct\n",
            "Sentença 16: O ministro da Defesa de Israel, Yoav Gal...\n",
            "\tToken 0: O - POS: DET - DEP: det\n",
            "\tToken 1: ministro - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: da - POS: ADP - DEP: case\n",
            "\tToken 3: Defesa - POS: PROPN - DEP: nmod\n",
            "\tToken 4: de - POS: ADP - DEP: case\n",
            "\tToken 5: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 6: , - POS: PUNCT - DEP: punct\n",
            "\tToken 7: Yoav - POS: PROPN - DEP: appos\n",
            "\tToken 8: Gallant - POS: PROPN - DEP: flat:name\n",
            "\tToken 9: , - POS: PUNCT - DEP: punct\n",
            "\tToken 10: disse - POS: VERB - DEP: ROOT\n",
            "\tToken 11: que - POS: SCONJ - DEP: mark\n",
            "\tToken 12: \" - POS: NUM - DEP: nummod\n",
            "\tToken 13: muito - POS: ADV - DEP: advmod\n",
            "\tToken 14: poucos - POS: DET - DEP: det\n",
            "\tToken 15: danos - POS: NOUN - DEP: nsubj:pass\n",
            "\tToken 16: foram - POS: AUX - DEP: aux:pass\n",
            "\tToken 17: causados - POS: VERB - DEP: ccomp\n",
            "\tToken 18: \" - POS: NUM - DEP: obj\n",
            "\tToken 19: , - POS: PUNCT - DEP: punct\n",
            "\tToken 20: mas - POS: CCONJ - DEP: cc\n",
            "\tToken 21: alertou - POS: VERB - DEP: conj\n",
            "\tToken 22: que - POS: SCONJ - DEP: mark\n",
            "\tToken 23: \" - POS: NUM - DEP: nsubj\n",
            "\tToken 24: a - POS: DET - DEP: det\n",
            "\tToken 25: campanha - POS: NOUN - DEP: nsubj\n",
            "\tToken 26: ainda - POS: ADV - DEP: advmod\n",
            "\tToken 27: não - POS: ADV - DEP: advmod\n",
            "\tToken 28: terminou - POS: VERB - DEP: ccomp\n",
            "\tToken 29: \" - POS: NUM - DEP: obj\n",
            "\tToken 30: e - POS: CCONJ - DEP: cc\n",
            "\tToken 31: disse - POS: VERB - DEP: conj\n",
            "\tToken 32: que - POS: SCONJ - DEP: mark\n",
            "\tToken 33: Israel - POS: PROPN - DEP: nsubj\n",
            "\tToken 34: deve - POS: VERB - DEP: ccomp\n",
            "\tToken 35: \" - POS: PRON - DEP: mark\n",
            "\tToken 36: permanecer - POS: VERB - DEP: ccomp\n",
            "\tToken 37: alerta - POS: VERB - DEP: xcomp\n",
            "\tToken 38: \" - POS: NOUN - DEP: obj\n",
            "\tToken 39: . - POS: PUNCT - DEP: punct\n",
            "Sentença 17: Quase todos Ao expressar forte condenaçã...\n",
            "\tToken 0: Quase - POS: ADV - DEP: advmod\n",
            "\tToken 1: todos - POS: PRON - DEP: dep\n",
            "\tToken 2: Ao - POS: SCONJ - DEP: mark\n",
            "\tToken 3: expressar - POS: VERB - DEP: advcl\n",
            "\tToken 4: forte - POS: ADJ - DEP: advmod\n",
            "\tToken 5: condenação - POS: NOUN - DEP: obj\n",
            "\tToken 6: pelo - POS: ADP - DEP: case\n",
            "\tToken 7: ataque - POS: NOUN - DEP: nmod\n",
            "\tToken 8: , - POS: PUNCT - DEP: punct\n",
            "\tToken 9: o - POS: DET - DEP: det\n",
            "\tToken 10: presidente - POS: NOUN - DEP: nsubj\n",
            "\tToken 11: dos - POS: ADP - DEP: case\n",
            "\tToken 12: Estados - POS: PROPN - DEP: nmod\n",
            "\tToken 13: Unidos - POS: PROPN - DEP: flat:name\n",
            "\tToken 14: , - POS: PUNCT - DEP: punct\n",
            "\tToken 15: Joe - POS: PROPN - DEP: appos\n",
            "\tToken 16: Biden - POS: PROPN - DEP: flat:name\n",
            "\tToken 17: , - POS: PUNCT - DEP: punct\n",
            "\tToken 18: disse - POS: VERB - DEP: ROOT\n",
            "\tToken 19: que - POS: SCONJ - DEP: mark\n",
            "\tToken 20: os - POS: DET - DEP: det\n",
            "\tToken 21: EUA - POS: PROPN - DEP: nsubj\n",
            "\tToken 22: ajudaram - POS: VERB - DEP: ccomp\n",
            "\tToken 23: Israel - POS: PROPN - DEP: obj\n",
            "\tToken 24: \" - POS: PROPN - DEP: flat:name\n",
            "\tToken 25: a - POS: SCONJ - DEP: mark\n",
            "\tToken 26: derrubar - POS: VERB - DEP: advcl\n",
            "\tToken 27: quase - POS: ADV - DEP: advmod\n",
            "\tToken 28: todos - POS: DET - DEP: det\n",
            "\tToken 29: \" - POS: NUM - DEP: obj\n",
            "\tToken 30: os - POS: DET - DEP: det\n",
            "\tToken 31: mísseis - POS: NOUN - DEP: obj\n",
            "\tToken 32: e - POS: CCONJ - DEP: cc\n",
            "\tToken 33: drones - POS: NOUN - DEP: conj\n",
            "\tToken 34: . - POS: PUNCT - DEP: punct\n",
            "Sentença 18: \"...\n",
            "\tToken 0: \" - POS: NUM - DEP: ROOT\n",
            "Sentença 19: O Irã e os seus representantes que opera...\n",
            "\tToken 0: O - POS: DET - DEP: det\n",
            "\tToken 1: Irã - POS: PROPN - DEP: nsubj\n",
            "\tToken 2: e - POS: CCONJ - DEP: cc\n",
            "\tToken 3: os - POS: DET - DEP: det\n",
            "\tToken 4: seus - POS: DET - DEP: det\n",
            "\tToken 5: representantes - POS: NOUN - DEP: conj\n",
            "\tToken 6: que - POS: PRON - DEP: nsubj\n",
            "\tToken 7: operam - POS: VERB - DEP: acl:relcl\n",
            "\tToken 8: a - POS: ADP - DEP: case\n",
            "\tToken 9: partir - POS: VERB - DEP: obl\n",
            "\tToken 10: do - POS: ADP - DEP: case\n",
            "\tToken 11: Iêmen - POS: PROPN - DEP: nmod\n",
            "\tToken 12: , - POS: PUNCT - DEP: punct\n",
            "\tToken 13: Síria - POS: PROPN - DEP: conj\n",
            "\tToken 14: e - POS: CCONJ - DEP: cc\n",
            "\tToken 15: Iraque - POS: PROPN - DEP: conj\n",
            "\tToken 16: lançaram - POS: VERB - DEP: ccomp\n",
            "\tToken 17: um - POS: DET - DEP: det\n",
            "\tToken 18: ataque - POS: NOUN - DEP: obj\n",
            "\tToken 19: aéreo - POS: ADJ - DEP: amod\n",
            "\tToken 20: sem - POS: ADP - DEP: case\n",
            "\tToken 21: precedentes - POS: NOUN - DEP: nmod\n",
            "\tToken 22: contra - POS: ADP - DEP: case\n",
            "\tToken 23: instalações - POS: NOUN - DEP: nmod\n",
            "\tToken 24: militares - POS: ADJ - DEP: amod\n",
            "\tToken 25: em - POS: ADP - DEP: case\n",
            "\tToken 26: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 27: \" - POS: PROPN - DEP: flat:name\n",
            "\tToken 28: , - POS: PUNCT - DEP: punct\n",
            "\tToken 29: disse - POS: VERB - DEP: ROOT\n",
            "\tToken 30: Biden - POS: PROPN - DEP: nsubj\n",
            "\tToken 31: . - POS: PUNCT - DEP: punct\n",
            "Sentença 20: Em um comunicado oficial, o Irã afirmou ...\n",
            "\tToken 0: Em - POS: ADP - DEP: case\n",
            "\tToken 1: um - POS: DET - DEP: det\n",
            "\tToken 2: comunicado - POS: NOUN - DEP: obl\n",
            "\tToken 3: oficial - POS: ADJ - DEP: amod\n",
            "\tToken 4: , - POS: PUNCT - DEP: punct\n",
            "\tToken 5: o - POS: DET - DEP: det\n",
            "\tToken 6: Irã - POS: PROPN - DEP: nsubj\n",
            "\tToken 7: afirmou - POS: VERB - DEP: ROOT\n",
            "\tToken 8: que - POS: SCONJ - DEP: mark\n",
            "\tToken 9: o - POS: DET - DEP: det\n",
            "\tToken 10: ataque - POS: NOUN - DEP: nsubj:pass\n",
            "\tToken 11: foi - POS: AUX - DEP: aux:pass\n",
            "\tToken 12: nomeado - POS: VERB - DEP: ccomp\n",
            "\tToken 13: \" - POS: PUNCT - DEP: punct\n",
            "\tToken 14: Operação - POS: PROPN - DEP: nsubj:pass\n",
            "\tToken 15: Promessa - POS: PROPN - DEP: flat:name\n",
            "\tToken 16: Verdadeira - POS: PROPN - DEP: flat:name\n",
            "\tToken 17: \" - POS: PROPN - DEP: flat:name\n",
            "\tToken 18: e - POS: CCONJ - DEP: cc\n",
            "\tToken 19: disse - POS: VERB - DEP: conj\n",
            "\tToken 20: que - POS: SCONJ - DEP: mark\n",
            "\tToken 21: lançou - POS: VERB - DEP: ccomp\n",
            "\tToken 22: \" - POS: NUM - DEP: obj\n",
            "\tToken 23: dezenas - POS: PRON - DEP: obj\n",
            "\tToken 24: de - POS: ADP - DEP: case\n",
            "\tToken 25: mísseis - POS: NOUN - DEP: nmod\n",
            "\tToken 26: e - POS: CCONJ - DEP: cc\n",
            "\tToken 27: drones - POS: NOUN - DEP: conj\n",
            "\tToken 28: contra - POS: ADP - DEP: case\n",
            "\tToken 29: alvos - POS: NOUN - DEP: nmod\n",
            "\tToken 30: específicos - POS: ADJ - DEP: amod\n",
            "\tToken 31: \" - POS: NUM - DEP: obj\n",
            "\tToken 32: em - POS: ADP - DEP: case\n",
            "\tToken 33: Israel - POS: PROPN - DEP: obl\n",
            "\tToken 34: . - POS: PUNCT - DEP: punct\n",
            "Sentença 21: A declaração militar do Irã diz que o at...\n",
            "\tToken 0: A - POS: DET - DEP: det\n",
            "\tToken 1: declaração - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: militar - POS: ADJ - DEP: amod\n",
            "\tToken 3: do - POS: ADP - DEP: case\n",
            "\tToken 4: Irã - POS: PROPN - DEP: nmod\n",
            "\tToken 5: diz - POS: VERB - DEP: ROOT\n",
            "\tToken 6: que - POS: SCONJ - DEP: mark\n",
            "\tToken 7: o - POS: DET - DEP: det\n",
            "\tToken 8: ataque - POS: NOUN - DEP: nsubj\n",
            "\tToken 9: está - POS: AUX - DEP: aux\n",
            "\tToken 10: relacionado - POS: VERB - DEP: ccomp\n",
            "\tToken 11: a - POS: DET - DEP: det\n",
            "\tToken 12: \" - POS: PUNCT - DEP: nummod\n",
            "\tToken 13: crimes - POS: NOUN - DEP: obj\n",
            "\tToken 14: repetidos - POS: VERB - DEP: acl\n",
            "\tToken 15: \" - POS: NUM - DEP: obj\n",
            "\tToken 16: de - POS: ADP - DEP: case\n",
            "\tToken 17: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 18: , - POS: PUNCT - DEP: punct\n",
            "\tToken 19: incluindo - POS: VERB - DEP: acl\n",
            "\tToken 20: o - POS: DET - DEP: det\n",
            "\tToken 21: ataque - POS: NOUN - DEP: obj\n",
            "\tToken 22: em - POS: ADP - DEP: case\n",
            "\tToken 23: 1º - POS: ADJ - DEP: obl\n",
            "\tToken 24: de - POS: ADP - DEP: case\n",
            "\tToken 25: abril - POS: NOUN - DEP: nmod\n",
            "\tToken 26: ao - POS: ADP - DEP: case\n",
            "\tToken 27: consulado - POS: NOUN - DEP: obj\n",
            "\tToken 28: iraniano - POS: ADJ - DEP: amod\n",
            "\tToken 29: , - POS: PUNCT - DEP: punct\n",
            "\tToken 30: que - POS: PRON - DEP: obj\n",
            "\tToken 31: Teerã - POS: PROPN - DEP: nsubj\n",
            "\tToken 32: atribuiu - POS: VERB - DEP: acl:relcl\n",
            "\tToken 33: a - POS: ADP - DEP: case\n",
            "\tToken 34: Israel - POS: PROPN - DEP: obj\n",
            "\tToken 35: . - POS: PUNCT - DEP: punct\n",
            "Sentença 22: Devido aos ataques, os espaços aéreos fo...\n",
            "\tToken 0: Devido - POS: ADV - DEP: advmod\n",
            "\tToken 1: aos - POS: ADP - DEP: case\n",
            "\tToken 2: ataques - POS: NOUN - DEP: obl\n",
            "\tToken 3: , - POS: PUNCT - DEP: punct\n",
            "\tToken 4: os - POS: DET - DEP: det\n",
            "\tToken 5: espaços - POS: NOUN - DEP: nsubj:pass\n",
            "\tToken 6: aéreos - POS: ADJ - DEP: amod\n",
            "\tToken 7: foram - POS: AUX - DEP: aux:pass\n",
            "\tToken 8: fechados - POS: VERB - DEP: ROOT\n",
            "\tToken 9: em - POS: ADP - DEP: case\n",
            "\tToken 10: todo - POS: DET - DEP: det\n",
            "\tToken 11: o - POS: DET - DEP: fixed\n",
            "\tToken 12: Oriente - POS: PROPN - DEP: obl\n",
            "\tToken 13: Médio - POS: PROPN - DEP: flat:name\n",
            "\tToken 14: no - POS: ADP - DEP: case\n",
            "\tToken 15: sábado - POS: NOUN - DEP: obl\n",
            "\tToken 16: . - POS: PUNCT - DEP: punct\n",
            "Sentença 23: A Jordânia, o Líbano e o Iraque, três pa...\n",
            "\tToken 0: A - POS: DET - DEP: det\n",
            "\tToken 1: Jordânia - POS: PROPN - DEP: nsubj\n",
            "\tToken 2: , - POS: PUNCT - DEP: punct\n",
            "\tToken 3: o - POS: DET - DEP: det\n",
            "\tToken 4: Líbano - POS: PROPN - DEP: conj\n",
            "\tToken 5: e - POS: CCONJ - DEP: cc\n",
            "\tToken 6: o - POS: DET - DEP: det\n",
            "\tToken 7: Iraque - POS: PROPN - DEP: conj\n",
            "\tToken 8: , - POS: PUNCT - DEP: punct\n",
            "\tToken 9: três - POS: NUM - DEP: nummod\n",
            "\tToken 10: países - POS: NOUN - DEP: conj\n",
            "\tToken 11: localizados - POS: VERB - DEP: acl\n",
            "\tToken 12: na - POS: ADP - DEP: case\n",
            "\tToken 13: provável - POS: ADJ - DEP: amod\n",
            "\tToken 14: trajetória - POS: NOUN - DEP: obl\n",
            "\tToken 15: de - POS: ADP - DEP: case\n",
            "\tToken 16: voo - POS: NOUN - DEP: nmod\n",
            "\tToken 17: destes - POS: ADP - DEP: case\n",
            "\tToken 18: drones - POS: NOUN - DEP: nmod\n",
            "\tToken 19: , - POS: PUNCT - DEP: punct\n",
            "\tToken 20: fecharam - POS: VERB - DEP: ROOT\n",
            "\tToken 21: o - POS: DET - DEP: det\n",
            "\tToken 22: seu - POS: DET - DEP: det\n",
            "\tToken 23: espaço - POS: NOUN - DEP: obj\n",
            "\tToken 24: aéreo - POS: ADJ - DEP: amod\n",
            "\tToken 25: . - POS: PUNCT - DEP: punct\n",
            "Sentença 24: O Irã e Israel também fecharam os seus p...\n",
            "\tToken 0: O - POS: DET - DEP: det\n",
            "\tToken 1: Irã - POS: PROPN - DEP: nsubj\n",
            "\tToken 2: e - POS: CCONJ - DEP: cc\n",
            "\tToken 3: Israel - POS: PROPN - DEP: conj\n",
            "\tToken 4: também - POS: ADV - DEP: advmod\n",
            "\tToken 5: fecharam - POS: VERB - DEP: ROOT\n",
            "\tToken 6: os - POS: DET - DEP: det\n",
            "\tToken 7: seus - POS: DET - DEP: obj\n",
            "\tToken 8: para - POS: ADP - DEP: case\n",
            "\tToken 9: todos - POS: PRON - DEP: obl\n",
            "\tToken 10: , - POS: PUNCT - DEP: punct\n",
            "\tToken 11: exceto - POS: ADP - DEP: case\n",
            "\tToken 12: aeronaves - POS: NOUN - DEP: obl\n",
            "\tToken 13: militares - POS: NOUN - DEP: amod\n",
            "\tToken 14: . - POS: PUNCT - DEP: punct\n",
            "Sentença 25: O Conselho de Segurança da ONU se reunir...\n",
            "\tToken 0: O - POS: DET - DEP: det\n",
            "\tToken 1: Conselho - POS: PROPN - DEP: nsubj\n",
            "\tToken 2: de - POS: ADP - DEP: case\n",
            "\tToken 3: Segurança - POS: PROPN - DEP: nmod\n",
            "\tToken 4: da - POS: ADP - DEP: case\n",
            "\tToken 5: ONU - POS: PROPN - DEP: nmod\n",
            "\tToken 6: se - POS: PRON - DEP: expl\n",
            "\tToken 7: reunirá - POS: VERB - DEP: parataxis\n",
            "\tToken 8: , - POS: PUNCT - DEP: punct\n",
            "\tToken 9: neste - POS: ADP - DEP: case\n",
            "\tToken 10: domingo - POS: NOUN - DEP: obl\n",
            "\tToken 11: ( - POS: PUNCT - DEP: punct\n",
            "\tToken 12: 14/3 - POS: NOUN - DEP: appos\n",
            "\tToken 13: ) - POS: PUNCT - DEP: punct\n",
            "\tToken 14: , - POS: PUNCT - DEP: punct\n",
            "\tToken 15: para - POS: ADP - DEP: case\n",
            "\tToken 16: uma - POS: DET - DEP: det\n",
            "\tToken 17: reunião - POS: NOUN - DEP: obl\n",
            "\tToken 18: de - POS: ADP - DEP: case\n",
            "\tToken 19: emergência - POS: NOUN - DEP: nmod\n",
            "\tToken 20: sobre - POS: ADP - DEP: case\n",
            "\tToken 21: o - POS: DET - DEP: det\n",
            "\tToken 22: ataque - POS: NOUN - DEP: nmod\n",
            "\tToken 23: do - POS: ADP - DEP: case\n",
            "\tToken 24: Irã - POS: PROPN - DEP: nmod\n",
            "\tToken 25: a - POS: ADP - DEP: case\n",
            "\tToken 26: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 27: , - POS: PUNCT - DEP: punct\n",
            "\tToken 28: disse - POS: VERB - DEP: ROOT\n",
            "\tToken 29: sua - POS: DET - DEP: det\n",
            "\tToken 30: presidente - POS: NOUN - DEP: nsubj\n",
            "\tToken 31: , - POS: PUNCT - DEP: punct\n",
            "\tToken 32: Vanessa - POS: PROPN - DEP: appos\n",
            "\tToken 33: Frazier - POS: PROPN - DEP: flat:name\n",
            "\tToken 34: . - POS: PUNCT - DEP: punct\n",
            "Sentença 26: Desdobramento da guerra em Gaza...\n",
            "\tToken 0: Desdobramento - POS: NOUN - DEP: ROOT\n",
            "\tToken 1: da - POS: ADP - DEP: case\n",
            "\tToken 2: guerra - POS: NOUN - DEP: nmod\n",
            "\tToken 3: em - POS: ADP - DEP: case\n",
            "\tToken 4: Gaza - POS: PROPN - DEP: nmod\n",
            "Sentença 27: Entre os inúmeros desdobramentos da guer...\n",
            "\tToken 0: Entre - POS: ADP - DEP: case\n",
            "\tToken 1: os - POS: DET - DEP: det\n",
            "\tToken 2: inúmeros - POS: ADJ - DEP: amod\n",
            "\tToken 3: desdobramentos - POS: NOUN - DEP: obl\n",
            "\tToken 4: da - POS: ADP - DEP: case\n",
            "\tToken 5: guerra - POS: NOUN - DEP: nmod\n",
            "\tToken 6: de - POS: ADP - DEP: case\n",
            "\tToken 7: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 8: contra - POS: ADP - DEP: case\n",
            "\tToken 9: o - POS: DET - DEP: det\n",
            "\tToken 10: Hamas - POS: PROPN - DEP: nmod\n",
            "\tToken 11: na - POS: ADP - DEP: case\n",
            "\tToken 12: Faixa - POS: PROPN - DEP: nmod\n",
            "\tToken 13: Gaza - POS: PROPN - DEP: flat:name\n",
            "\tToken 14: , - POS: PUNCT - DEP: punct\n",
            "\tToken 15: a - POS: DET - DEP: det\n",
            "\tToken 16: intensificação - POS: NOUN - DEP: nsubj:pass\n",
            "\tToken 17: da - POS: ADP - DEP: case\n",
            "\tToken 18: inimizade - POS: NOUN - DEP: nmod\n",
            "\tToken 19: entre - POS: ADP - DEP: case\n",
            "\tToken 20: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 21: e - POS: CCONJ - DEP: cc\n",
            "\tToken 22: o - POS: DET - DEP: det\n",
            "\tToken 23: Irã - POS: PROPN - DEP: conj\n",
            "\tToken 24: é - POS: AUX - DEP: aux:pass\n",
            "\tToken 25: considerada - POS: VERB - DEP: ccomp\n",
            "\tToken 26: a - POS: ADP - DEP: det\n",
            "\tToken 27: mais - POS: ADV - DEP: advmod\n",
            "\tToken 28: explosiva - POS: NOUN - DEP: xcomp\n",
            "\tToken 29: , - POS: PUNCT - DEP: punct\n",
            "\tToken 30: escreve - POS: VERB - DEP: ROOT\n",
            "\tToken 31: a - POS: DET - DEP: det\n",
            "\tToken 32: correspondente - POS: NOUN - DEP: nsubj\n",
            "\tToken 33: internacional - POS: ADJ - DEP: amod\n",
            "\tToken 34: da - POS: ADP - DEP: case\n",
            "\tToken 35: BBC - POS: PROPN - DEP: nmod\n",
            "\tToken 36: Lyse - POS: PROPN - DEP: appos\n",
            "\tToken 37: Doucet - POS: PROPN - DEP: flat:name\n",
            "\tToken 38: . - POS: PUNCT - DEP: punct\n",
            "Sentença 28: Os países têm uma grande rivalidade há a...\n",
            "\tToken 0: Os - POS: DET - DEP: det\n",
            "\tToken 1: países - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: têm - POS: VERB - DEP: ROOT\n",
            "\tToken 3: uma - POS: DET - DEP: det\n",
            "\tToken 4: grande - POS: ADJ - DEP: amod\n",
            "\tToken 5: rivalidade - POS: NOUN - DEP: obj\n",
            "\tToken 6: há - POS: VERB - DEP: advcl\n",
            "\tToken 7: anos - POS: NOUN - DEP: obj\n",
            "\tToken 8: , - POS: PUNCT - DEP: punct\n",
            "\tToken 9: o - POS: PRON - DEP: appos\n",
            "\tToken 10: que - POS: PRON - DEP: nsubj\n",
            "\tToken 11: já - POS: ADV - DEP: advmod\n",
            "\tToken 12: deixou - POS: VERB - DEP: acl:relcl\n",
            "\tToken 13: um - POS: DET - DEP: det\n",
            "\tToken 14: grande - POS: ADJ - DEP: amod\n",
            "\tToken 15: número - POS: NOUN - DEP: obj\n",
            "\tToken 16: de - POS: ADP - DEP: case\n",
            "\tToken 17: mortos - POS: NOUN - DEP: nmod\n",
            "\tToken 18: , - POS: PUNCT - DEP: punct\n",
            "\tToken 19: muitas - POS: ADP - DEP: det\n",
            "\tToken 20: vezes - POS: NOUN - DEP: obl\n",
            "\tToken 21: em - POS: ADP - DEP: case\n",
            "\tToken 22: ações - POS: NOUN - DEP: obl\n",
            "\tToken 23: secretas - POS: ADJ - DEP: amod\n",
            "\tToken 24: em - POS: ADP - DEP: case\n",
            "\tToken 25: que - POS: SCONJ - DEP: obl\n",
            "\tToken 26: nenhum - POS: PRON - DEP: nsubj\n",
            "\tToken 27: dos - POS: ADP - DEP: case\n",
            "\tToken 28: governos - POS: NOUN - DEP: nmod\n",
            "\tToken 29: admite - POS: VERB - DEP: acl:relcl\n",
            "\tToken 30: sua - POS: DET - DEP: det\n",
            "\tToken 31: responsabilidade - POS: NOUN - DEP: obj\n",
            "\tToken 32: . - POS: PUNCT - DEP: punct\n",
            "Sentença 29: Desde que a guerra em Gaza eclodiu há se...\n",
            "\tToken 0: Desde - POS: SCONJ - DEP: mark\n",
            "\tToken 1: que - POS: SCONJ - DEP: fixed\n",
            "\tToken 2: a - POS: DET - DEP: det\n",
            "\tToken 3: guerra - POS: NOUN - DEP: nsubj\n",
            "\tToken 4: em - POS: ADP - DEP: case\n",
            "\tToken 5: Gaza - POS: PROPN - DEP: nmod\n",
            "\tToken 6: eclodiu - POS: VERB - DEP: advcl\n",
            "\tToken 7: há - POS: ADP - DEP: case\n",
            "\tToken 8: seis - POS: NUM - DEP: nummod\n",
            "\tToken 9: meses - POS: NOUN - DEP: obl\n",
            "\tToken 10: , - POS: PUNCT - DEP: punct\n",
            "\tToken 11: Israel - POS: PROPN - DEP: nsubj\n",
            "\tToken 12: intensificou - POS: VERB - DEP: ROOT\n",
            "\tToken 13: os - POS: DET - DEP: det\n",
            "\tToken 14: seus - POS: DET - DEP: det\n",
            "\tToken 15: movimentos - POS: NOUN - DEP: obj\n",
            "\tToken 16: contra - POS: ADP - DEP: case\n",
            "\tToken 17: o - POS: DET - DEP: det\n",
            "\tToken 18: Irã - POS: PROPN - DEP: nmod\n",
            "\tToken 19: , - POS: PUNCT - DEP: punct\n",
            "\tToken 20: não - POS: ADV - DEP: advmod\n",
            "\tToken 21: apenas - POS: ADV - DEP: advmod\n",
            "\tToken 22: atacando - POS: VERB - DEP: advcl\n",
            "\tToken 23: o - POS: DET - DEP: det\n",
            "\tToken 24: fornecimento - POS: NOUN - DEP: obj\n",
            "\tToken 25: de - POS: ADP - DEP: case\n",
            "\tToken 26: armas - POS: NOUN - DEP: nmod\n",
            "\tToken 27: e - POS: CCONJ - DEP: cc\n",
            "\tToken 28: infraestruturas - POS: NOUN - DEP: conj\n",
            "\tToken 29: na - POS: ADP - DEP: case\n",
            "\tToken 30: Síria - POS: PROPN - DEP: nmod\n",
            "\tToken 31: , - POS: PUNCT - DEP: punct\n",
            "\tToken 32: mas - POS: CCONJ - DEP: cc\n",
            "\tToken 33: assassinando - POS: VERB - DEP: conj\n",
            "\tToken 34: altos - POS: ADJ - DEP: obj\n",
            "\tToken 35: comandantes - POS: NOUN - DEP: amod\n",
            "\tToken 36: do - POS: ADP - DEP: case\n",
            "\tToken 37: Corpo - POS: PROPN - DEP: nmod\n",
            "\tToken 38: da - POS: ADP - DEP: case\n",
            "\tToken 39: Guarda - POS: PROPN - DEP: nmod\n",
            "\tToken 40: Revolucionária - POS: PROPN - DEP: flat:name\n",
            "\tToken 41: Islâmica - POS: PROPN - DEP: flat:name\n",
            "\tToken 42: ( - POS: PUNCT - DEP: punct\n",
            "\tToken 43: IRGC - POS: PROPN - DEP: appos\n",
            "\tToken 44: ) - POS: PUNCT - DEP: punct\n",
            "\tToken 45: do - POS: ADP - DEP: case\n",
            "\tToken 46: Irã - POS: PROPN - DEP: nmod\n",
            "\tToken 47: e - POS: CCONJ - DEP: cc\n",
            "\tToken 48: do - POS: ADP - DEP: case\n",
            "\tToken 49: Hezbollah - POS: PROPN - DEP: conj\n",
            "\tToken 50: ( - POS: PUNCT - DEP: punct\n",
            "\tToken 51: organização - POS: NOUN - DEP: appos\n",
            "\tToken 52: política - POS: ADJ - DEP: amod\n",
            "\tToken 53: e - POS: CCONJ - DEP: cc\n",
            "\tToken 54: paramilitar - POS: VERB - DEP: conj\n",
            "\tToken 55: fundamentalista - POS: NOUN - DEP: obj\n",
            "\tToken 56: islâmica - POS: ADJ - DEP: amod\n",
            "\tToken 57: , - POS: PUNCT - DEP: punct\n",
            "\tToken 58: criada - POS: VERB - DEP: acl\n",
            "\tToken 59: no - POS: ADP - DEP: case\n",
            "\tToken 60: Irã - POS: PROPN - DEP: obl\n",
            "\tToken 61: e - POS: CCONJ - DEP: cc\n",
            "\tToken 62: presente - POS: ADJ - DEP: conj\n",
            "\tToken 63: no - POS: ADP - DEP: case\n",
            "\tToken 64: Líbano - POS: PROPN - DEP: obl\n",
            "\tToken 65: ) - POS: PUNCT - DEP: punct\n",
            "\tToken 66: . - POS: PUNCT - DEP: punct\n",
            "Sentença 30: O Irã então apreendeu um navio comercial...\n",
            "\tToken 0: O - POS: DET - DEP: det\n",
            "\tToken 1: Irã - POS: PROPN - DEP: nsubj\n",
            "\tToken 2: então - POS: ADV - DEP: advmod\n",
            "\tToken 3: apreendeu - POS: VERB - DEP: ROOT\n",
            "\tToken 4: um - POS: DET - DEP: det\n",
            "\tToken 5: navio - POS: NOUN - DEP: obj\n",
            "\tToken 6: comercial - POS: ADJ - DEP: amod\n",
            "\tToken 7: com - POS: ADP - DEP: case\n",
            "\tToken 8: ligações - POS: NOUN - DEP: nmod\n",
            "\tToken 9: a - POS: ADP - DEP: case\n",
            "\tToken 10: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 11: na - POS: ADP - DEP: case\n",
            "\tToken 12: manhã - POS: NOUN - DEP: nmod\n",
            "\tToken 13: de - POS: ADP - DEP: case\n",
            "\tToken 14: sábado - POS: NOUN - DEP: nmod\n",
            "\tToken 15: ( - POS: PUNCT - DEP: punct\n",
            "\tToken 16: 13/4 - POS: NOUN - DEP: appos\n",
            "\tToken 17: ) - POS: PUNCT - DEP: punct\n",
            "\tToken 18: , - POS: PUNCT - DEP: punct\n",
            "\tToken 19: mas - POS: CCONJ - DEP: cc\n",
            "\tToken 20: analistas - POS: NOUN - DEP: nsubj\n",
            "\tToken 21: já - POS: ADV - DEP: advmod\n",
            "\tToken 22: afirmavam - POS: VERB - DEP: conj\n",
            "\tToken 23: que - POS: SCONJ - DEP: mark\n",
            "\tToken 24: era - POS: AUX - DEP: cop\n",
            "\tToken 25: pouco - POS: ADV - DEP: advmod\n",
            "\tToken 26: provável - POS: ADJ - DEP: ccomp\n",
            "\tToken 27: que - POS: SCONJ - DEP: mark\n",
            "\tToken 28: Teerã - POS: PROPN - DEP: nsubj\n",
            "\tToken 29: considerasse - POS: VERB - DEP: csubj\n",
            "\tToken 30: esta - POS: DET - DEP: det\n",
            "\tToken 31: uma - POS: DET - DEP: det\n",
            "\tToken 32: \" - POS: NOUN - DEP: amod\n",
            "\tToken 33: resposta - POS: NOUN - DEP: obj\n",
            "\tToken 34: apropriada - POS: VERB - DEP: acl\n",
            "\tToken 35: \" - POS: NUM - DEP: obl\n",
            "\tToken 36: aos - POS: ADP - DEP: case\n",
            "\tToken 37: últimos - POS: ADJ - DEP: amod\n",
            "\tToken 38: atos - POS: NOUN - DEP: iobj\n",
            "\tToken 39: de - POS: ADP - DEP: case\n",
            "\tToken 40: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 41: . - POS: PUNCT - DEP: punct\n",
            "Sentença 31: O especialista israelense Raz Zimmt, pes...\n",
            "\tToken 0: O - POS: DET - DEP: det\n",
            "\tToken 1: especialista - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: israelense - POS: ADJ - DEP: amod\n",
            "\tToken 3: Raz - POS: PROPN - DEP: appos\n",
            "\tToken 4: Zimmt - POS: PROPN - DEP: flat:name\n",
            "\tToken 5: , - POS: PUNCT - DEP: punct\n",
            "\tToken 6: pesquisador - POS: NOUN - DEP: appos\n",
            "\tToken 7: sênior - POS: ADJ - DEP: amod\n",
            "\tToken 8: do - POS: ADP - DEP: case\n",
            "\tToken 9: Instituto - POS: PROPN - DEP: nmod\n",
            "\tToken 10: de - POS: ADP - DEP: case\n",
            "\tToken 11: Segurança - POS: PROPN - DEP: nmod\n",
            "\tToken 12: Nacional - POS: PROPN - DEP: flat:name\n",
            "\tToken 13: em - POS: ADP - DEP: case\n",
            "\tToken 14: Tel - POS: PROPN - DEP: nmod\n",
            "\tToken 15: Aviv - POS: PROPN - DEP: flat:name\n",
            "\tToken 16: , - POS: PUNCT - DEP: punct\n",
            "\tToken 17: alertou - POS: VERB - DEP: ROOT\n",
            "\tToken 18: que - POS: SCONJ - DEP: mark\n",
            "\tToken 19: o - POS: DET - DEP: det\n",
            "\tToken 20: Irã - POS: PROPN - DEP: nsubj\n",
            "\tToken 21: agiria - POS: VERB - DEP: ccomp\n",
            "\tToken 22: com - POS: ADP - DEP: case\n",
            "\tToken 23: força - POS: NOUN - DEP: obl\n",
            "\tToken 24: . - POS: PUNCT - DEP: punct\n",
            "Sentença 32: \"...\n",
            "\tToken 0: \" - POS: NUM - DEP: ROOT\n",
            "Sentença 33: A paciência dos iranianos esgotou-se dia...\n",
            "\tToken 0: A - POS: DET - DEP: det\n",
            "\tToken 1: paciência - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: dos - POS: ADP - DEP: case\n",
            "\tToken 3: iranianos - POS: NOUN - DEP: nmod\n",
            "\tToken 4: esgotou-se - POS: VERB - DEP: parataxis\n",
            "\tToken 5: diante - POS: ADV - DEP: advmod\n",
            "\tToken 6: dos - POS: DET - DEP: det\n",
            "\tToken 7: reveses - POS: NOUN - DEP: obj\n",
            "\tToken 8: atribuídos - POS: VERB - DEP: acl\n",
            "\tToken 9: a - POS: ADP - DEP: case\n",
            "\tToken 10: Israel - POS: PROPN - DEP: obj\n",
            "\tToken 11: \" - POS: PROPN - DEP: flat:name\n",
            "\tToken 12: , - POS: PUNCT - DEP: punct\n",
            "\tToken 13: disse - POS: VERB - DEP: ROOT\n",
            "\tToken 14: o - POS: DET - DEP: det\n",
            "\tToken 15: pesquisador - POS: NOUN - DEP: nsubj\n",
            "\tToken 16: em - POS: ADP - DEP: case\n",
            "\tToken 17: rede - POS: NOUN - DEP: obl\n",
            "\tToken 18: social - POS: ADJ - DEP: amod\n",
            "\tToken 19: . - POS: PUNCT - DEP: punct\n",
            "Sentença 34: Origem da Rivalidade Israel e Irã estão ...\n",
            "\tToken 0: Origem - POS: PROPN - DEP: nsubj\n",
            "\tToken 1: da - POS: ADP - DEP: case\n",
            "\tToken 2: Rivalidade - POS: PROPN - DEP: nmod\n",
            "\tToken 3: Israel - POS: PROPN - DEP: flat:name\n",
            "\tToken 4: e - POS: CCONJ - DEP: cc\n",
            "\tToken 5: Irã - POS: PROPN - DEP: conj\n",
            "\tToken 6: estão - POS: AUX - DEP: aux\n",
            "\tToken 7: há - POS: VERB - DEP: ROOT\n",
            "\tToken 8: anos - POS: NOUN - DEP: obj\n",
            "\tToken 9: em - POS: ADP - DEP: case\n",
            "\tToken 10: uma - POS: DET - DEP: det\n",
            "\tToken 11: rivalidade - POS: NOUN - DEP: obl\n",
            "\tToken 12: sangrenta - POS: ADJ - DEP: amod\n",
            "\tToken 13: que - POS: PRON - DEP: nsubj\n",
            "\tToken 14: virou - POS: VERB - DEP: acl:relcl\n",
            "\tToken 15: uma - POS: NUM - DEP: obj\n",
            "\tToken 16: das - POS: ADP - DEP: case\n",
            "\tToken 17: principais - POS: ADJ - DEP: amod\n",
            "\tToken 18: fontes - POS: NOUN - DEP: nmod\n",
            "\tToken 19: de - POS: ADP - DEP: case\n",
            "\tToken 20: instabilidade - POS: NOUN - DEP: nmod\n",
            "\tToken 21: no - POS: ADP - DEP: case\n",
            "\tToken 22: Oriente - POS: PROPN - DEP: nmod\n",
            "\tToken 23: Médio - POS: PROPN - DEP: flat:name\n",
            "\tToken 24: e - POS: CCONJ - DEP: cc\n",
            "\tToken 25: cuja - POS: DET - DEP: det\n",
            "\tToken 26: intensidade - POS: NOUN - DEP: nsubj\n",
            "\tToken 27: varia - POS: VERB - DEP: conj\n",
            "\tToken 28: de - POS: ADP - DEP: case\n",
            "\tToken 29: acordo - POS: NOUN - DEP: obl\n",
            "\tToken 30: com - POS: ADP - DEP: case\n",
            "\tToken 31: o - POS: DET - DEP: det\n",
            "\tToken 32: momento - POS: NOUN - DEP: nmod\n",
            "\tToken 33: geopolítico - POS: ADJ - DEP: amod\n",
            "\tToken 34: . - POS: PUNCT - DEP: punct\n",
            "Sentença 35: As relações entre Israel e o Irã foram b...\n",
            "\tToken 0: As - POS: DET - DEP: det\n",
            "\tToken 1: relações - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: entre - POS: ADP - DEP: case\n",
            "\tToken 3: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 4: e - POS: CCONJ - DEP: cc\n",
            "\tToken 5: o - POS: DET - DEP: det\n",
            "\tToken 6: Irã - POS: PROPN - DEP: conj\n",
            "\tToken 7: foram - POS: AUX - DEP: cop\n",
            "\tToken 8: bastante - POS: ADV - DEP: advmod\n",
            "\tToken 9: cordiais - POS: ADJ - DEP: ROOT\n",
            "\tToken 10: até - POS: ADP - DEP: case\n",
            "\tToken 11: 1979 - POS: NUM - DEP: obl\n",
            "\tToken 12: , - POS: PUNCT - DEP: punct\n",
            "\tToken 13: quando - POS: ADV - DEP: advmod\n",
            "\tToken 14: a - POS: DET - DEP: det\n",
            "\tToken 15: chamada - POS: ADJ - DEP: amod\n",
            "\tToken 16: Revolução - POS: PROPN - DEP: nsubj\n",
            "\tToken 17: Islâmica - POS: PROPN - DEP: flat:name\n",
            "\tToken 18: dos - POS: ADP - DEP: case\n",
            "\tToken 19: aiatolás - POS: NOUN - DEP: nmod\n",
            "\tToken 20: conquistou - POS: VERB - DEP: advcl\n",
            "\tToken 21: o - POS: DET - DEP: det\n",
            "\tToken 22: poder - POS: NOUN - DEP: obj\n",
            "\tToken 23: em - POS: ADP - DEP: case\n",
            "\tToken 24: Teerã - POS: PROPN - DEP: obl\n",
            "\tToken 25: . - POS: PUNCT - DEP: punct\n",
            "Sentença 36: E embora tenha se oposto ao plano de fat...\n",
            "\tToken 0: E - POS: CCONJ - DEP: cc\n",
            "\tToken 1: embora - POS: SCONJ - DEP: mark\n",
            "\tToken 2: tenha - POS: VERB - DEP: advcl\n",
            "\tToken 3: se - POS: SCONJ - DEP: expl\n",
            "\tToken 4: oposto - POS: ADJ - DEP: xcomp\n",
            "\tToken 5: ao - POS: ADP - DEP: case\n",
            "\tToken 6: plano - POS: NOUN - DEP: obl\n",
            "\tToken 7: de - POS: ADP - DEP: case\n",
            "\tToken 8: fatiamento - POS: NOUN - DEP: nmod\n",
            "\tToken 9: da - POS: ADP - DEP: case\n",
            "\tToken 10: Palestina - POS: PROPN - DEP: nmod\n",
            "\tToken 11: que - POS: PRON - DEP: nsubj\n",
            "\tToken 12: resultou - POS: VERB - DEP: acl:relcl\n",
            "\tToken 13: na - POS: ADP - DEP: case\n",
            "\tToken 14: criação - POS: NOUN - DEP: obj\n",
            "\tToken 15: do - POS: ADP - DEP: case\n",
            "\tToken 16: Estado - POS: NOUN - DEP: nmod\n",
            "\tToken 17: de - POS: ADP - DEP: case\n",
            "\tToken 18: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 19: em - POS: ADP - DEP: case\n",
            "\tToken 20: 1948 - POS: NUM - DEP: nmod\n",
            "\tToken 21: , - POS: PUNCT - DEP: punct\n",
            "\tToken 22: o - POS: DET - DEP: det\n",
            "\tToken 23: Irã - POS: PROPN - DEP: nsubj\n",
            "\tToken 24: foi - POS: AUX - DEP: cop\n",
            "\tToken 25: o - POS: DET - DEP: det\n",
            "\tToken 26: segundo - POS: ADJ - DEP: amod\n",
            "\tToken 27: país - POS: NOUN - DEP: ROOT\n",
            "\tToken 28: islâmico - POS: ADJ - DEP: amod\n",
            "\tToken 29: a - POS: SCONJ - DEP: mark\n",
            "\tToken 30: reconhecer - POS: VERB - DEP: acl\n",
            "\tToken 31: Israel - POS: PROPN - DEP: obj\n",
            "\tToken 32: , - POS: PUNCT - DEP: punct\n",
            "\tToken 33: depois - POS: ADV - DEP: advmod\n",
            "\tToken 34: do - POS: ADP - DEP: case\n",
            "\tToken 35: Egito - POS: PROPN - DEP: obl\n",
            "\tToken 36: . - POS: PUNCT - DEP: punct\n",
            "Sentença 37: O Irã era uma monarquia na qual reinavam...\n",
            "\tToken 0: O - POS: DET - DEP: det\n",
            "\tToken 1: Irã - POS: PROPN - DEP: nsubj\n",
            "\tToken 2: era - POS: AUX - DEP: cop\n",
            "\tToken 3: uma - POS: DET - DEP: det\n",
            "\tToken 4: monarquia - POS: NOUN - DEP: ROOT\n",
            "\tToken 5: na - POS: ADP - DEP: case\n",
            "\tToken 6: qual - POS: PRON - DEP: obl\n",
            "\tToken 7: reinavam - POS: VERB - DEP: acl:relcl\n",
            "\tToken 8: os - POS: DET - DEP: det\n",
            "\tToken 9: xás - POS: NOUN - DEP: obj\n",
            "\tToken 10: da - POS: ADP - DEP: case\n",
            "\tToken 11: dinastia - POS: NOUN - DEP: nmod\n",
            "\tToken 12: Pahlavi - POS: PROPN - DEP: appos\n",
            "\tToken 13: e - POS: CCONJ - DEP: cc\n",
            "\tToken 14: um - POS: NUM - DEP: conj\n",
            "\tToken 15: dos - POS: ADP - DEP: case\n",
            "\tToken 16: principais - POS: ADJ - DEP: amod\n",
            "\tToken 17: aliados - POS: NOUN - DEP: nmod\n",
            "\tToken 18: dos - POS: ADP - DEP: case\n",
            "\tToken 19: Estados - POS: PROPN - DEP: nmod\n",
            "\tToken 20: Unidos - POS: PROPN - DEP: flat:name\n",
            "\tToken 21: no - POS: ADP - DEP: case\n",
            "\tToken 22: Oriente - POS: PROPN - DEP: nmod\n",
            "\tToken 23: Médio - POS: PROPN - DEP: flat:name\n",
            "\tToken 24: . - POS: PUNCT - DEP: punct\n",
            "Sentença 38: Assim, o fundador de Israel e seu primei...\n",
            "\tToken 0: Assim - POS: ADV - DEP: advmod\n",
            "\tToken 1: , - POS: PUNCT - DEP: punct\n",
            "\tToken 2: o - POS: DET - DEP: det\n",
            "\tToken 3: fundador - POS: NOUN - DEP: nsubj\n",
            "\tToken 4: de - POS: ADP - DEP: case\n",
            "\tToken 5: Israel - POS: PROPN - DEP: nmod\n",
            "\tToken 6: e - POS: CCONJ - DEP: cc\n",
            "\tToken 7: seu - POS: DET - DEP: det\n",
            "\tToken 8: primeiro - POS: ADJ - DEP: amod\n",
            "\tToken 9: chefe - POS: NOUN - DEP: conj\n",
            "\tToken 10: de - POS: ADP - DEP: case\n",
            "\tToken 11: governo - POS: NOUN - DEP: nmod\n",
            "\tToken 12: , - POS: PUNCT - DEP: punct\n",
            "\tToken 13: David - POS: PROPN - DEP: appos\n",
            "\tToken 14: Ben-Gurion - POS: PROPN - DEP: flat:name\n",
            "\tToken 15: , - POS: PUNCT - DEP: punct\n",
            "\tToken 16: procurou - POS: VERB - DEP: ROOT\n",
            "\tToken 17: e - POS: CCONJ - DEP: cc\n",
            "\tToken 18: conseguiu - POS: VERB - DEP: conj\n",
            "\tToken 19: a - POS: DET - DEP: det\n",
            "\tToken 20: amizade - POS: NOUN - DEP: obj\n",
            "\tToken 21: iraniana - POS: ADJ - DEP: amod\n",
            "\tToken 22: como - POS: ADP - DEP: case\n",
            "\tToken 23: forma - POS: NOUN - DEP: obl\n",
            "\tToken 24: de - POS: SCONJ - DEP: mark\n",
            "\tToken 25: combater - POS: VERB - DEP: acl\n",
            "\tToken 26: a - POS: DET - DEP: det\n",
            "\tToken 27: rejeição - POS: NOUN - DEP: obj\n",
            "\tToken 28: do - POS: ADP - DEP: case\n",
            "\tToken 29: novo - POS: ADJ - DEP: amod\n",
            "\tToken 30: Estado - POS: NOUN - DEP: nmod\n",
            "\tToken 31: judeu - POS: ADJ - DEP: amod\n",
            "\tToken 32: de - POS: ADP - DEP: case\n",
            "\tToken 33: seus - POS: DET - DEP: det\n",
            "\tToken 34: vizinhos - POS: NOUN - DEP: nmod\n",
            "\tToken 35: árabes - POS: ADJ - DEP: amod\n",
            "\tToken 36: . - POS: PUNCT - DEP: punct\n",
            "Sentença 39: Mas a Revolução de Ruhollah Khomeini, em...\n",
            "\tToken 0: Mas - POS: CCONJ - DEP: cc\n",
            "\tToken 1: a - POS: DET - DEP: det\n",
            "\tToken 2: Revolução - POS: PROPN - DEP: nsubj\n",
            "\tToken 3: de - POS: ADP - DEP: case\n",
            "\tToken 4: Ruhollah - POS: PROPN - DEP: nmod\n",
            "\tToken 5: Khomeini - POS: PROPN - DEP: flat:name\n",
            "\tToken 6: , - POS: PUNCT - DEP: punct\n",
            "\tToken 7: em - POS: ADP - DEP: case\n",
            "\tToken 8: 1979 - POS: NUM - DEP: nmod\n",
            "\tToken 9: , - POS: PUNCT - DEP: punct\n",
            "\tToken 10: derrubou - POS: VERB - DEP: ROOT\n",
            "\tToken 11: o - POS: DET - DEP: det\n",
            "\tToken 12: xá - POS: PROPN - DEP: obj\n",
            "\tToken 13: e - POS: CCONJ - DEP: cc\n",
            "\tToken 14: impôs - POS: VERB - DEP: conj\n",
            "\tToken 15: uma - POS: DET - DEP: det\n",
            "\tToken 16: república - POS: NOUN - DEP: obj\n",
            "\tToken 17: islâmica - POS: ADJ - DEP: amod\n",
            "\tToken 18: que - POS: PRON - DEP: nsubj\n",
            "\tToken 19: se - POS: PRON - DEP: expl\n",
            "\tToken 20: apresentava - POS: VERB - DEP: acl:relcl\n",
            "\tToken 21: como - POS: ADP - DEP: case\n",
            "\tToken 22: defensora - POS: NOUN - DEP: xcomp\n",
            "\tToken 23: dos - POS: ADP - DEP: case\n",
            "\tToken 24: oprimidos - POS: NOUN - DEP: nmod\n",
            "\tToken 25: e - POS: CCONJ - DEP: cc\n",
            "\tToken 26: tinha - POS: VERB - DEP: conj\n",
            "\tToken 27: como - POS: ADP - DEP: case\n",
            "\tToken 28: principais - POS: ADJ - DEP: amod\n",
            "\tToken 29: marcas - POS: NOUN - DEP: xcomp\n",
            "\tToken 30: a - POS: DET - DEP: det\n",
            "\tToken 31: rejeição - POS: NOUN - DEP: obj\n",
            "\tToken 32: ao - POS: ADP - DEP: case\n",
            "\tToken 33: \" - POS: PUNCT - DEP: nummod\n",
            "\tToken 34: imperialismo - POS: NOUN - DEP: nmod\n",
            "\tToken 35: \" - POS: NUM - DEP: appos\n",
            "\tToken 36: americano - POS: ADJ - DEP: amod\n",
            "\tToken 37: e - POS: CCONJ - DEP: cc\n",
            "\tToken 38: a - POS: ADP - DEP: case\n",
            "\tToken 39: Israel - POS: PROPN - DEP: conj\n",
            "\tToken 40: . - POS: PUNCT - DEP: punct\n",
            "Sentença 40: Teerã então passou a considerar que Isra...\n",
            "\tToken 0: Teerã - POS: NOUN - DEP: nsubj\n",
            "\tToken 1: então - POS: ADV - DEP: advmod\n",
            "\tToken 2: passou - POS: VERB - DEP: ROOT\n",
            "\tToken 3: a - POS: SCONJ - DEP: mark\n",
            "\tToken 4: considerar - POS: VERB - DEP: xcomp\n",
            "\tToken 5: que - POS: SCONJ - DEP: mark\n",
            "\tToken 6: Israel - POS: PROPN - DEP: nsubj\n",
            "\tToken 7: não - POS: ADV - DEP: advmod\n",
            "\tToken 8: tem - POS: VERB - DEP: ccomp\n",
            "\tToken 9: o - POS: DET - DEP: det\n",
            "\tToken 10: direito - POS: NOUN - DEP: obj\n",
            "\tToken 11: de - POS: SCONJ - DEP: mark\n",
            "\tToken 12: existir - POS: VERB - DEP: acl\n",
            "\tToken 13: . - POS: PUNCT - DEP: punct\n",
            "Sentença 41: Os governantes iranianos consideram o pa...\n",
            "\tToken 0: Os - POS: DET - DEP: det\n",
            "\tToken 1: governantes - POS: NOUN - DEP: nsubj\n",
            "\tToken 2: iranianos - POS: ADJ - DEP: amod\n",
            "\tToken 3: consideram - POS: VERB - DEP: ROOT\n",
            "\tToken 4: o - POS: DET - DEP: det\n",
            "\tToken 5: país - POS: NOUN - DEP: obj\n",
            "\tToken 6: o - POS: DET - DEP: det\n",
            "\tToken 7: \" - POS: PUNCT - DEP: det\n",
            "\tToken 8: pequeno - POS: ADJ - DEP: amod\n",
            "\tToken 9: Satanás - POS: PROPN - DEP: obj\n",
            "\tToken 10: \" - POS: X - DEP: flat:name\n",
            "\tToken 11: , - POS: PUNCT - DEP: punct\n",
            "\tToken 12: o - POS: DET - DEP: det\n",
            "\tToken 13: aliado - POS: NOUN - DEP: appos\n",
            "\tToken 14: no - POS: ADP - DEP: case\n",
            "\tToken 15: Oriente - POS: PROPN - DEP: nmod\n",
            "\tToken 16: Médio - POS: PROPN - DEP: flat:name\n",
            "\tToken 17: dos - POS: ADP - DEP: case\n",
            "\tToken 18: Estados - POS: PROPN - DEP: nmod\n",
            "\tToken 19: Unidos - POS: PROPN - DEP: flat:name\n",
            "\tToken 20: , - POS: PUNCT - DEP: punct\n",
            "\tToken 21: que - POS: PRON - DEP: nsubj\n",
            "\tToken 22: chamam - POS: VERB - DEP: acl:relcl\n",
            "\tToken 23: de - POS: ADP - DEP: case\n",
            "\tToken 24: \" - POS: NOUN - DEP: det\n",
            "\tToken 25: grande - POS: ADJ - DEP: amod\n",
            "\tToken 26: Satanás - POS: PROPN - DEP: obj\n",
            "\tToken 27: \" - POS: PROPN - DEP: flat:name\n",
            "\tToken 28: . - POS: PUNCT - DEP: punct\n",
            "Sentença 42: Já Israel acusa o Irã de \"financiar grup...\n",
            "\tToken 0: Já - POS: ADV - DEP: advmod\n",
            "\tToken 1: Israel - POS: PROPN - DEP: nsubj\n",
            "\tToken 2: acusa - POS: VERB - DEP: ROOT\n",
            "\tToken 3: o - POS: DET - DEP: det\n",
            "\tToken 4: Irã - POS: PROPN - DEP: obj\n",
            "\tToken 5: de - POS: ADP - DEP: case\n",
            "\tToken 6: \" - POS: PROPN - DEP: nmod\n",
            "\tToken 7: financiar - POS: VERB - DEP: xcomp\n",
            "\tToken 8: grupos - POS: NOUN - DEP: obj\n",
            "\tToken 9: terroristas - POS: ADJ - DEP: amod\n",
            "\tToken 10: \" - POS: NUM - DEP: dep\n",
            "\tToken 11: e - POS: CCONJ - DEP: cc\n",
            "\tToken 12: de - POS: SCONJ - DEP: mark\n",
            "\tToken 13: realizar - POS: VERB - DEP: conj\n",
            "\tToken 14: ataques - POS: NOUN - DEP: obj\n",
            "\tToken 15: contra - POS: ADP - DEP: case\n",
            "\tToken 16: seus - POS: DET - DEP: det\n",
            "\tToken 17: interesses - POS: NOUN - DEP: nmod\n",
            "\tToken 18: , - POS: PUNCT - DEP: punct\n",
            "\tToken 19: movidos - POS: VERB - DEP: acl\n",
            "\tToken 20: pelo - POS: ADP - DEP: case\n",
            "\tToken 21: antissemitismo - POS: NOUN - DEP: obl:agent\n",
            "\tToken 22: dos - POS: ADP - DEP: case\n",
            "\tToken 23: aiatolás - POS: NOUN - DEP: nmod\n",
            "\tToken 24: . - POS: PUNCT - DEP: punct\n"
          ]
        }
      ],
      "source": [
        "for index, sent in enumerate(doc.sents):\n",
        "    print(f\"Sentença {index}: {sent.text[:40]}...\")\n",
        "\n",
        "    for token_index, token in enumerate(sent):\n",
        "        print(\n",
        "            f\"\\tToken {token_index}: {token.text} - POS: {token.pos_} - DEP: {token.dep_}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Extração de tópicos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIy6qrndJieD",
        "outputId": "254479f9-ce5e-4f20-a439-547493389d6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frequência das palavras:\n",
            "primeira: 0.02631578947368421\n",
            "vez: 0.02631578947368421\n",
            "irã: 0.5263157894736842\n",
            "realizou: 0.02631578947368421\n",
            "ataques: 0.07894736842105263\n"
          ]
        }
      ],
      "source": [
        "stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
        "\n",
        "tokens = nltk.word_tokenize(text, language=\"portuguese\")\n",
        "tokens = [token.lower() for token in tokens if token.isalpha()]  # remove pontuação\n",
        "tokens = [token for token in tokens if token not in stopwords]  # remove stopwords\n",
        "\n",
        "word_frequencies = {}\n",
        "\n",
        "for word in tokens:\n",
        "    if word not in word_frequencies.keys():\n",
        "        word_frequencies[word] = 1\n",
        "    else:\n",
        "        word_frequencies[word] += 1\n",
        "\n",
        "maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = word_frequencies[word] / maximum_frequncy\n",
        "\n",
        "print(\"Frequência das palavras:\")\n",
        "\n",
        "for w, f in list(word_frequencies.items())[:5]:\n",
        "    print(f\"{w}: {f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tópicos do texto: \n",
            "Palavra 0: israel\n",
            "Palavra 1: irã\n",
            "Palavra 2: disse\n",
            "Palavra 3: ataque\n",
            "Palavra 4: contra\n",
            "Palavra 5: sábado\n",
            "Palavra 6: drones\n",
            "Palavra 7: mísseis\n",
            "Palavra 8: iraque\n",
            "Palavra 9: síria\n",
            "Palavra 10: todos\n",
            "Palavra 11: grande\n",
            "Palavra 12: teerã\n",
            "Palavra 13: oriente\n",
            "Palavra 14: médio\n"
          ]
        }
      ],
      "source": [
        "best_words = heapq.nlargest(15, word_frequencies, key=word_frequencies.get)\n",
        "\n",
        "print(\"Tópicos do texto: \")\n",
        "\n",
        "for index, word in enumerate(best_words):\n",
        "    print(f\"Palavra {index}: {word}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Resumo do texto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVG8pyuJP-CR",
        "outputId": "5f5f54ae-98f5-467c-b466-6814b3602691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frequência das palavras: \n",
            "israel: 38\n",
            "irã: 20\n",
            "disse: 13\n",
            "ataque: 10\n",
            "contra: 7\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "frequencia = Counter(tokens)\n",
        "\n",
        "print(f\"Frequência das palavras: \")\n",
        "\n",
        "for palavra, freq in frequencia.most_common()[:5]:\n",
        "    print(f\"{palavra}: {freq}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv2GXqXyQ-ZM",
        "outputId": "7220c0bc-a7ea-44d2-fa22-eb125ab22dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentença: Pela primeira vez, o Irã realizou ataques diretos contra o território de Israel neste sábado (13/4). - Score: 2.1052631578947367\n",
            "Sentença: No meio da noite de sábado, alertas de ataque aéreo dispararam em Israel. - Score: 1.5789473684210527\n",
            "Sentença: Os residentes procuraram abrigo enquanto explosões eram ouvidas e as defesas aéreas eram ativadas. - Score: 0.2631578947368421\n",
            "Sentença: As interceptações iluminaram o céu noturno em vários lugares do país, enquanto muitos drones e mísseis foram abatidos pelos aliados de Israel antes de chegarem ao território israelense. - Score: 1.8421052631578947\n",
            "Sentença: Uma represália era esperada. - Score: 0.05263157894736842\n"
          ]
        }
      ],
      "source": [
        "sentence_list = nltk.sent_tokenize(text)\n",
        "\n",
        "sentence_scores = {}\n",
        "for sent in sentence_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(\" \")) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]\n",
        "\n",
        "for sent, score in list(sentence_scores.items())[:5]:\n",
        "    print(f\"Sentença: {sent} - Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU3OdIVCR4-b",
        "outputId": "e7c982bd-31b3-4e7c-d8ba-68de658d6bae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sumário do texto\n",
            "Hagari disse que o ataque em larga escala foi uma \"grande escalada\" e disse que Israel e seus aliados operaram com força total para defender Israel. \"O Irã e os seus representantes que operam a partir do Iêmen, Síria e Iraque lançaram um ataque aéreo sem precedentes contra instalações militares em Israel\", disse Biden. Em um comunicado oficial, o Irã afirmou que o ataque foi nomeado \"Operação Promessa Verdadeira\" e disse que lançou \"dezenas de mísseis e drones contra alvos específicos\" em Israel.\n"
          ]
        }
      ],
      "source": [
        "TOP_SENTENCES = 3\n",
        "\n",
        "summary_sentences = heapq.nlargest(\n",
        "    TOP_SENTENCES, sentence_scores, key=sentence_scores.get\n",
        ")\n",
        "\n",
        "print(\"Sumário do texto\")\n",
        "\n",
        "summary = \" \".join(summary_sentences)\n",
        "\n",
        "print(summary)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
